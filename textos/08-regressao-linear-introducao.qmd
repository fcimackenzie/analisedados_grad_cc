---
title: "Modelos e Modelagem Estatística"
author: Mário Olímpio de Menezes
section-titles: false
number-sections: false
format: 
  beamer:
    theme: CambridgeUS
    fonttheme: structurebold
    classoption: 10pt
    highlight: tango
    toc: false
    slide_level: 2
    navigation: horizontal

knitr: 
   opts_chunk: 
     collapse: true
     strip.white: true
     tidy: true
     comment: ""
     continue: false
     warning: false
     message: false
     fontsize: scriptsize

---





# Pensando em Modelos {.unnumbered}


## O que é um Modelo

* Um modelo é uma representação conceitual (simplificada) do mundo ou de parte do mundo.
* Efetivamente, qualquer *conceituação* prove um modelo
* Mas a maioria dos modelos provê pouca discernibilidade, nenhum ganho de predição e nenhum entendimento mais profundo.
* Considere o caso dos **Provérbios com Opostos**:
    + Quem não arrisca, não petisca.
    + Prevenir é melhor do que remediar.
    
    A maioria (todos?) os provérbios tem um oposto, uma contradição. Ou seja, não há poder de discernimento aqui!!! (i.e., quando se olha só uma parte do provérbio.)

* O que se busca com modelos é alavancar o discernimento sobre o mundo ou pelo menos sobre um subsistema em que o mundo opera.


<!-- Model Thinking --> 
<!-- slides sobre Synergetics and Model Thinking de CJ Fearnley - 2012 Sep 30 -->
<!-- On-line version of this presentation:
http://www.CJFearnley.com/Asheville.Synergetics.Model.Thinking.pdf -->

<!-- os slides iniciais são baseados no material acima --> 

## Modelos Certos e Errados

* "Essencialmente todos os modelos estão errados, mas alguns são úteis" --- George E.P.Box
* Todos os modelos são corretos, mas alguns provêem melhor ganho ou clareza ou *insight* em alguns aspectos do sistema modelado do que outros.
* Ou seja, a questão com modelos é de que modo ele provê um melhor entendimento do que vários outros modelos do sistema em questão? 
    + Quais são as forças e as fraquezas do modelo?
    
### Pensar com Modelos

* Pensar com Modelos é **usar toda a caixa de ferramentas cheia de modelos para ajudar a pensar em diferentes situações**

<!-- Os slides a seguir peguei do livro Modeling Complex Systems - pg 4 - Introduction - 1.2 What is a model? -->

## Construção de Modelos

* Em sistema real (mundo físico, sociedade, meio ambiente), existem muitos aspectos que provavelmente importantes.
    + Nem todos eles, contudo, devem ser incluídos em um modelo.
* Somente algumas poucas partes relevantes, que (pensamos) têm um papel essencial na interpretação dos fenômenos observados devem ser retidos.
* Modelos são diferentes (distintos) do que normalmente chamamos de *simulação*. 
    + E esta distinção, para esclarecermos bem, vamos usar um *exemplo de livro*.

## Construção de Modelos

### Modelo *vs* Simulação

* Suponha que você queira saber quantas focas podem ser abatidas anualmente de uma população sem ameaçar sua sobrevivência futura, seria necessário ter uma descrição daquela população naquele ambiente com muitos detalhes.
    * Taxas específicas de nascimento e mortalidade por idade e conhecimento de como estas taxas variam com a densidade da população e com outros aspectos do ambiente que poderão se alterar no futuro
* Todas estas informações poderiam ser incluidas em uma simulação da população, que, poderia, então ser utilizada para prever os efeitos das políticas específicos de manejo.

## Construção de Modelos

\small

### Modelo *vs* Simulação

* O valor de tais simulações é óbvio, mas sua utilidade está principalmente na análise de casos particulares.
* Uma teoria de ecologia deve fazer afirmações sobre ecosistemas como um todo, bem como sobre espécies em momentos específicos.
    + \color{blue}{E ela deve fazer afirmações que são verdadeiras para muitas espécies diferentes e não somente para uma.}
* Qualquer ecosistema real contem muitas espécies, que interagem de muitos modos, para que uma simulação seja uma abordagem prática.
* Quanto melhor uma simulação for para o propósito específico, pela inclusão de todos os detalhes relevantes, tanto mais difícil será generalizar suas conclusões para outras espécies.
* Portanto, para a descoberta de ideias gerais em ecologia, muitos tipos diferentes de descrições matemáticas (modelos), são necessários.


**\alert{Enquanto uma boa simulação deve incluir tantos detalhes quanto possível, um bom modelo deve incluir tão poucos quanto possível!}**

<!-- The R Book 2nd Edition - -->

# Modelagem Estatística

## Esclarecimentos

\small

* O termo Modelagem Estatística, conforme empregado aqui, significa a construção de um modelo matemático, expresso por relacionamento entre variáveis explicativas, cujo objetivo é conseguir explicar a variabilidade de alguma variável resposta.
    + Buscamos construir o melhor modelo que forneça os melhores resultados quando o empregarmos para prever valores desconhecidos da variável resposta a partir de novas variáveis explicativas.
* O termo **Estatística** neste contexto significa que não estamos criando nenhuma **Lei Física** ou de qualquer outra natureza, que explique as causas da variabilidade da variável resposta.
* Por exemplo, um experimento que esteja coletando dados sobre uma  **Lei Física**, como a Lei de Newton, fará uso da estatística nos procedimentos de análise dos dados.
    + Tratamento de Incertezas e suas propagações;
    + Ajuste de funções, 
    + etc
    * \alert{Estes são usos da estatística!}


## Modelagem Estatística

* A parte mais difícil de qualquer trabalho estatístico é ... começar!
* E uma das coisas mais difíceis quando se começa é a escolha do tipo correto de análise estatística. A escolha depende:
    + da natureza dos dados
    + da questão que se quer responder, entre outras coisas.
* A chave é entender que tipo de variável *resposta* você tem e saber a natureza de suas variáveis *explicativas*.
    + A variável *resposta* é a coisa com a qual você está trabalhando:
        + é a variável cuja variação você está tentando entender!
        + é a variável que vai no eixo *y* do gráfico.
    + A variável *explicativa* vai no eixo *x* do gráfico.
        + você está interessado na extensão em que a variação da variável *resposta* está associada com a variação da variável *explicativa*.

## Modelagem Estatística

* Você também precisa considerar o *modo* que as variáveis na sua análise medem o que elas se propõe a medir.
* Uma medida contínua é uma variável do tipo altura ou peso que pode assumir valores com números reais.
* Uma variável categórica é um fator com dois ou mais níveis: 
    + sexo é um fator com dois níveis (masculino e feminino)
    + cor pode ser um fator com sete níveis (vermelho, laranja, amarelo, verde, azul, índigo e violeta)
* Portanto, é essencial responder às seguintes questões:
    + Qual das variáveis é a variável resposta?
    + Quais são as variáveis explicativas?
    + As variáveis explicativas são contínuas ou categóricas, ou uma mistura de ambas?
    + Que tipo de variável resposta temos: 
         + é uma medida contínua?  uma contagem?  uma proporção?  um tempo (ocasião) de morte?  ou uma categoria?

## Método Estatístico Apropriado

Algumas *chaves* simples para a escolha do método estatístico apropriado

### As variáveis explicativas

\small

1. Todas as variáveis explicativas são contínuas  $\Rightarrow$  **Regressão**
2. Todas as variáveis explicativas são categóricas $\Rightarrow$  **Análise de Variância (ANOVA)**
3. Variáveis explicativas são tanto contínuas como categóricas $\Rightarrow$  **Análise de Covariância (ANCOVA)**

\normalsize

### A variável resposta

\small

1. Contínua   $\Rightarrow$    **Regressão Normal, ANOVA ou ANCOVA**
2. Proporção $\Rightarrow$     **Regressão Logística**
3. Contagem  $\Rightarrow$     **Modelos log-linear**
4. Binária  $\Rightarrow$     **Análise logística binária**
5. Tempo na morte $\Rightarrow$   **Análise de sobrevivência**


<!-- No livro The R Book tem uma explicação sobre a Regressão Logística e o fato de utilizar a classificação "Variável Resposta do tipo Proporção" -->

<!--
An important class of problems involves count data on proportions such as:

* studies on death rates,
* infection rates of diseases,
* answers to questionnaires,
* proportion responding to clinical treatment,
* proportion admitting to particular voting intentions,
* sex ratios, or
* data on proportional response to an experimental treatment.

What all these have in common is that we know how many of the experimental objects are in one category (dead, insolvent, male or infected) and we also know how many are in another (alive, solvent, female or uninfected). This contrasts with Poisson count data, where we knew how many times an event occurred, but not how many times it did not occur (p. 579).


PROPORTION DATA     pag  633
16.5.1  Logistic regression with binomial errors

This example concerns sex ratios in insects (the proportion of all individuals that are males). In the species in question, it has been observed that the sex ratio is highly variable, and an experiment was set up to see whether population density was involved in determining the fraction of males.

numbers <- read.table("c:\\temp\\sexratio.txt",header=T)
attach(numbers)
head(numbers)

It certainly looks as if there are proportionally more males at high density, but we should plot the data as proportions to see this more clearly:

-->

## Objetivo da Modelagem Estatística

* O objetivo da modelagem é determinar os valores dos parâmetros em um modelo específico que *levam ao melhor ajuste do modelo aos dados*
* Os dados são *sacrosantos*; eles nos dizem o que realmente aconteceu sob determinadas circunstâncias.
    + É um erro comum dizer "os dados foram ajustados ao modelo" como se os dados fossem flexíveis, e nós tivéssemos uma estrutura clara do modelo.
    + É o contrário: o que se procura é o modelo mínimo adequado que descreva os dados.
    + O modelo é ajustado aos dados; não o contrário!
* O melhor modelo é o que produz o mínimo de variação não explicada (o *mínimo desvio dos resíduos*), sujeito à restrição de que todos os parâmetros no modelo devem ser estatisticamente significantes

## Especificando o modelo

\vspace{-0.5\baselineskip}
\small

* Um modelo embute nosso mecanismo de interpretação das variáveis explicativas envolvidas
    + E também que elas estão relacionadas à variável resposta.
* Buscamos um modelo **mínimo** por conta do princípio da *parcimônia*, e também um modelo **adequado** 
    + não há sentido em ter um modelo *inadequado*, que não descreve uma fração significante da variação dos dados.
* É muito importante entender que *não há **um** modelo*.
    + isso é um erro comum na regressão tradicional e ANOVA, reutilizar sem uma crítica do modelo.
    + em muitos casos, haverá um grande número de modelos diferentes, uns mais plausíveis do que outros, que podem ser ajustados a qualquer conjunto de dados.
* É preciso determinar quais, se algum, dos modelos possíveis são adequados
    + e depois, dos adequados, qual é o modelo mínimo adequado.
    + pode haver um conjunto de modelos que descrevem os dados igualmente bem (ou igualmente probremente se a variabilidade é grande)

## Primeiros passos

* Um erro muito comum é tentar fazer a modelagem estatística "logo de cara", sem pensar, direto!
* Ao invés disso, a melhor coisa a fazer é \color{blue}{gastar um tempo substancial}, logo de início, para entender os dados e o que eles mostram.
    + Isto vai ajudar a guiar o pensamento para a  modelagem estatística mais apropriada.


## Checklist da Modelagem Estatística 

### Checklist


* Certificar-se de que o dataframe está correto em estrutura e conteúdo:
    + Todos os valores de cada variável estão na mesma coluna?
    + Todos os zeros são realmente 0 ou deveriam ser `NA`?
    + Cada linha contém o mesmo número de entradas?
    + Existe algum nome de variável que contém espaço?
* Depois de carregar os dados:
    + Examine a estrutura com `str` e certifique-se de as classes e tipos das variáveis estão corretos.
    + Olhe no `head` e no `tail` dos dados e verifique possíveis erros.
    + Plote cada variável individualmente para verificar erros mais grosseiros (`plot(x)`, `plot(y)`, `boxplot`, etc)
    + Veja os relacionamentos entre as variáveis (use `tapply`, `plot`, `tree` e `gam`)
* Ou seja, explore os dados primeiro!

## Checklist da Modelagem Estatística

### Sobre o Modelo

* Pense sobre a escolha do modelo
    + Quais variáveis explicativas deveriam ser incluídas?
    + Que transformação da resposta é mais apropriada?
    + Que interações deveriam ser incluídas?
    + Quais termos não lineares deveriam ser incluídos?
    + Há alguma pseudo-replicação, e se houver, como se deve lidar com isso?
    + As variáveis explicativas deveriam ser transformadas?
* Tente utilizar o tipo mais simples de análise que seja apropriado para seus dados e para a questão que está tentando responder:
    + Faça uma ANOVA *one-way* ao invés de um modelo de efeitos mistos
* Ajuste um modelo máximo e vá simplificando-o paulatinamente ao remover parâmetros

## Checklist da Modelagem Estatística -- cont.

### Sobre o Modelo -- cont.

* Verifique o modelo mínimo adequado em termos de constância de variância e normalidade dos erros utilizando `plot(model)`
* Enfatize os tamanhos dos efeitos e erros padrões (`summary.lm`) e analise a tabela de desvios (`summary.aov`)
* Por fim, documente tudo o que fizer, e explique cada um dos passos. Desta maneira você entenderá o que fez e porque fez quando retornar à sua análise 6 meses mais tarde!

<!-- do livro Practical Regression and ANOVA with R - de Julian J. Faraway -->

# Regressão Linear


## Análise de Regressão

* A Análise de Regressão é utilizada para se explicar ou modelar o relacionamento entre uma única variável $Y$, chamada de variável *resposta*, *de saída* ou *dependente* e uma ou mais variáveis *preditoras*, *de entrada* ou *explicativas*, $X_1, X_2, ..., X_p$.
* Quando $p = 1$, é chamada regressão simples;
    + Quando $p > 1$ é chamada regressão múltipla ou algumas vezes, regressão multivariada.
* A variável resposta deve ser uma variável contínua
* As variáveis explicativas podem ser contínuas, discretas ou categóricas.

## Análise de Regressão - objetivos

### A Análise de Regressão tem vários possíveis objetivos, incluindo:

* Predição de observações futuras
* Avaliação do efeito de, ou do relacionamento entre, as variáveis explicativas sobre a resposta
* Uma descrição geral da estrutura dos dados

### História (em poucas linhas)

\footnotesize

* Problemas do tipo regressão foram abordados primeiramente no século 18, e estavam relacionados ao uso da astronomia na navegação.
* Legendre desenvolveu o método dos mínimos quadrados em 1805.
* Gauss disse que o tinha desenvolvido alguns anos antes e mostrou, em 1809, que os mínimos quadrados eram a solução ótima quando os erros tem uma distribuição normal.
* A metodologia ficou restrita às ciências físicas até a parte final do século 19, quando em 1875, Francis Galton cunhou o termo *regressão à mediocridade*. Pesquise na Wikipedia para saber mais sobre o contexto!


# Modelo Linear

## Modelo linear

Um **modelo linear** entre duas variáveis $X$ e $Y$, é definido
matematicamente como uma equação com dois parâmetros desconhecidos,


$$ y = b_0 + b_1x $$
que é uma estimativa da linha de regressão verdadeira da população:


$$\mu_y = \beta_0 + \beta_1 x$$

Esta linha de regressão descreve como a resposta média $\mu_y$ muda com $x$. 

Os valores observados para $y$ variam em torno da sua média $\mu_y$ e assumimos que tem o mesmo desvio padrão $\sigma$.

## Modelo linear

Os valores ajustados $b_0$ e $b_1$ estimam o verdadeiro *deslocamento* (*intercept*) e a inclinação da linha de regressão da população. 

Para fins de simplificação, indicamos $Y \equiv \mu_y$ na fórmula:

$$ Y = \beta_0 + \beta_1 X $$

Assim, dados $n$ pares de valores, $(X_1, Y_1), (X_2, Y_2), \ldots,
(X_n, Y_n)$, se for admitido que $Y$ é função linear de $X$, pode-se
estabelecer uma regressão linear simples, cujo modelo estatístico é


$$ Y_i = \beta_0 + \beta_1 X_i + e_i, \quad i = 1, 2, \ldots, n $$

## Modelo linear

* Para modelos simples, assumimos que:
    + A variância $y$ é constante
    + A variável explicativa $x$ é medida sem erro
    + A diferença entre um valor medido de $y$ e o valor predito pelo modelo para o mesmo valor de $x$ é chamado de *resíduo*
    + Resíduos são medidos na escala de $y$
    + Os resíduos são distribuídos normalmente.

## Ajustando um modelo linear

\small

Como através de uma amostra obtemos uma estimativa da verdadeira
equação de regressão, denominamos

$$\hat{Y}_i = \hat{\beta}_0 + \hat{\beta}_1 X_i $$

ou seja, $\hat{Y}_i$ é o valor **estimado** de $Y_i$, através das
**estimativas** de $\beta_0$ e $\beta_1$, que chamaremos de
$\hat{\beta}_0$ e $\hat{\beta}_1$. Para cada valor de $Y_i$, temos um
valor $\hat{Y}_i$ estimado pela equação de regressão,

$$Y_i = \hat{Y}_i + e_i $$

Ou seja, podemos expressar o modelo como: `DADOS = AJUSTE + RESÍDUO`, onde o termo `AJUSTE` representa a expressão $\beta_0 + \beta_1 X$. 

Portanto, o resíduo (ou desvio) de cada observação em relação ao modelo
adotado será


\footnotesize
$$\begin{array}{lll}
	e_i & = & Y_i - \hat{Y}_i \\
	e_i & = & Y_i - (\beta_0 + \beta_1 X_i)
\end{array} $$


## Ajustando um modelo linear -- primeira abordagem

Comumente se assume que os resíduos possuem uma distribuição normal com média zero e variância constante, ou seja, $e_i \sim \text{N}(0, \sigma^2)$.

A **solução de mínimos quadrados** vai determinar $\hat{\beta_0}$ e $\hat{\beta_1}$ que minimizam a soma dos quadrados dos resíduos (*residuals sum of squares* -- RSS):

$$\begin{array}{lll} \\
  RSS & = & \sum_{i=1}^n(Y_i - \hat{Y_i})^2 \\
      & = & \sum e_i^2
  \end{array}$$


O processo envolve a determinação dos seguintes valores (juntamente com o *RSS* acima), conhecidos como os "famosos cinco no R":


:::: {.columns}

::: {.column width="50%"}

* $\sum Y_i^2$
* $\sum Y_i$

:::

::: {.column width="50%"}

* $\sum X_i^2$
* $\sum X_i$
* $\sum X_iY_i$

:::

::::

## Somas corrigidas dos quadrados e soma dos produtos

* Depois dos famosos cinco, vamos calcular três somas essenciais "corrigidas".

$$ SSX = \sum x^2 - \frac{(\sum x)^2}{n}$$

$$ SSY = \sum y^2 - \frac{(\sum y)^2}{n}$$

* O terceiro termo é a soma corrigida dos produtos, $SSXY$. 

$$ SSXY = \sum xy - \frac{(\sum x)(\sum y)}{n} $$

## Somas corrigidas -- evitando erros de arredondamento

* As expressões para os cálculos das somas corrigidas e soma dos produtos envolvem cálculos computacionais potencialmente perigosos em termos de precisão.
* Subtrações de valores grandes podem gerar erros de arredondamento consideráveis.
* Para evitar isso, podemos utilizar as seguintes fórmulas equivalentes:

$$ SSY = \sum(y - \bar{y})^2$$
$$ SSX = \sum(x - \bar{x})^2$$
$$ SSXY = \sum(y - \bar{y})(x - \bar{x})$$

## Calculando os parâmetros

* Os parâmetros do modelo ($y = b_0 + b_1x$) podem ser determinados com os valores anteriores:

$$ b_1 = \frac{SSXY}{SSX}$$

* Uma parte da definição do melhor ajuste da linha reta é que ela passa através do ponto ($\bar{x},\bar{y}$), determinado pelos valores médios de $x$ e $y$.
* Como sabemos que $y = b_0 + b_1x$, então também temos que $\bar{y} = b_0 + b_1\bar{x}$. 
* Assim:

$$ b_0 = \bar{y} - b_1\bar{x} = \frac{\sum y}{n} - b_1\frac{\sum x}{n}$$


## Ajustando um modelo linear -- segunda abordagem


A **solução de mínimos quadrados**, resulta nas seguintes expressões para estimar os parâmetros $\beta_0$ e $\beta_1$:


$$\begin{array}{lll}
    \hat{\beta}_1 & = & \frac{\sum_{i=1}^{n} X_iY_i - \frac{\sum_{i=1}^{n} 
        X_i \sum_{i=1}^{n} Y_i}{n}}{\sum_{i=1}^{n}X_i^2 -
      \frac{(\sum_{i=1}^{n} X_i)^2}{n}} \\
      & & \\
    \hat{\beta_0} & = & \bar{Y} - \hat{\beta}_1 \bar{X}
\end{array}
$$

onde

$$
\begin{array}{lll}
    \bar{Y} & = & \frac{1}{n} \sum_{i=1}^{n} Y_i \qquad \text{e} \qquad \\
    \bar{X} & = & \frac{1}{n} \sum_{i=1}^{n} X_i
\end{array}
$$

## Verificando o ajuste do Modelo Linear


\small

Depois de ajustado um modelo linear, podemos nos perguntar:

* O quão bem ele ajusta os dados?
* Uma medida deste *ajuste* é o $R^2$:
    + O assim chamado *coeficiente de determinação ou percentual da variância explicada*
$$ R^2 = 1 - \frac{\sum(\hat{y}_i - y_i)^2}{\sum(y_i - \bar{y}^2)} = 1 - \frac{\mbox{RSS}}{\mbox{Total SS (corrigido p/ média)}} $$
   * RSS: *residual sum of squares* (soma dos quadrados dos resíduos)
   * SS: *sum of squares* 
* A faixa de $R^2$ é:  $0 \leq R^2 \leq 1$
    + Valores próximos a 1 indicam melhor ajuste.
    + Para regressão linear simples, $R^2 = r^2$, onde $r$ é a correlatção entre $x$ e $y$.
    + Esta definição de $R^2$ só faz sentido se o modelo tem um *intercept*.

<!-- adicionando abordagem do um curso da Yale (ANOVA for Regression) que tem uma boa descrição da ANOVA para análise de regressão:
http://www.stat.yale.edu/Courses/1997-98/101/anovareg.htm -->

## Análise de Variância para Regressão Linear


\small

* Para avaliar a significância do modelo, realizamos uma **Análise de Variância** (ANOVA) para a regressão. 
* Como vimos na estimação dos parâmetros, o objetivo é encontrar parâmetros que façam com que a soma de quadrados dos resíduos seja mínima.
* O conceito básico da regressão é `DADOS = AJUSTE + RESÍDUOS`, que podemos escrever como:
$$ (y_i - \bar{y}) = (\hat{y_i} - \bar{y}) + (y_i - \hat{y_i})$$
* O primeiro termo é a variação total na variável resposta $y$, o segundo termo é a variação na resposta média e o terceiro termo é o valor residual.
* Elevando ao quadrado e adicionando os termos para as $n$ observações temos:
$$\sum(y_i - \bar{y})^2 = \sum(\hat{y_i} - \bar{y})^2 + \sum(y_i - \hat{y_i})^2$$

## Análise de Variância para Regressão Linear

\small

* Podemos particionar a soma de quadrados da seguinte forma:


$$SST = SSM + RSS $$

* **SS** é *soma dos quadrados* e **T**, **M** e **R** são: **total, modelo e resíduos**, respectivamente.
* A variância da amostra $s_y^2$ é $\sum(y_i - \bar{y})^2/(n-1) = SST/DFT$, ou seja, a *soma total dos quadrados* dividida pelo *total de graus de liberdade* (DFT).
* Para regressão linear simples, a MSM (*média quadrada do modelo*) é $\sum(\hat{y_i} - \bar{y})^2/(1) = SSM/DFM$, já que um modelo de regressão linear simples tem apenas uma variável explicativa $x$.
* O *Erro quadrado médio* (MSE) é dado por $\sum(y_i - \hat{y_i})^2/(n-2) = RSS/DFE$, que é a estimativa da variância sobre a linha de regressão da população ($\sigma^2$).

## Análise de Variância  para Regressão Linear Simples


* Normalmente, os cálculos da ANOVA são mostrados em uma *tabela de análise de variância* que tem o seguinte formato para regressão linear **simples**:


\scriptsize

Fonte   |  Graus de Liberdade | Soma dos Quadrados | Quadrado Médio |  F 
--------|---------------------|--------------------|----------------|-----
Modelo  |         $1$         | $\sum(\hat{y_i}-\bar{y})^2$ | `SSM/DFM` |  `MSM/MSE`
Erro    |    $n-2$            | $\sum(y_i - \hat{y_i})^2$ | `RSS/DFE` | 
--------|---------------------|--------------------|----------------|-----
Total   |  $n-1$              | $\sum(y_i - \bar{y})^2$ | `SST/DFT` |   


\normalsize

* A coluna "F" provê uma estatística para testar a hipótese de que $\beta_1 \neq 0$ contra a hipótese nula de que $\beta_1 = 0$.

## Análise de Variância  para Regressão Linear Simples

* A estatística de teste é a razão `MSM/MSE`. Quando o termo `MSM` é grande relativamente ao termo `MSE`, então a razão é grande e há evidência contra a hipótese nula.
* Para regressão linear simples, a estatística `MSM/MSE` tem uma distribuição $F$ com os graus de liberdade dados por (`DFM`, `DFE`) = $(1, n-2)$.
    * O teste estatístico é comparar o valor da distribuição $F$ para estes graus de liberdade com o valor obtido acima.
    * No R isso é feito com a função `qf` que dá os quantis da distribuição $F$
* Outra possibilidade é verificar a probabilidade de se obter um valor de $F$ tão grande como o dado pela razão `MSM/MSE` com estes graus de liberdade. Neste caso utilizamos a função de distribuição de probabilidade acumulada ao invés dos quantis.
    * Como queremos a área de rejeição da hipótese, usamos `1 - pf`

<!-- Olhar o livro The R book - 2nd edition, o capitulo sobre regressao; parece bem interessante e completo; o capitulo sobre testes tb é muito bom. -->

# Praticando

## Análise de Regressão -- Exemplo 1

\small


* Vamos utilizar o conjunto de dados que mostra o crescimento de lagartas ("caterpillars")" alimentadas com uma dieta experimental que difere no conteúdo de *tannin*.


\scriptsize
```{r}
#| echo: true
#| eval: true
reg.data <- read.table("~/docs/cursos/tna5773/datasets/regression.txt", header=T)
names(reg.data)
X <- reg.data$tannin
Y <- reg.data$growth
n <- length(X)
```

## Análise de Regressão -- Exemplo 1

\small


Examinando os dados e fazendo no olho!


\footnotesize
\centering
```{r}
#| tidy: true
#| out-height: 6cm
#| echo: true
#| eval: true
plot(X, Y, pch=21, col='blue',bg="red")
```


## Análise de Regressão -- Exemplo 1

* Olhando o gráfico podemos fazer uma estimativa grosseira dos parâmetros *no olho*.

> * Quais as suas estimativas?
> * O conteúdo de *tannin* aumentou por 8 unidades, em resposta ao que o crescimento (`growth`) declinou de cerca de 12 unidades para 2 unidades.
> * Uma mudança de $-10$ unidades de crescimento!
> * A inclinação $b_1$ é a mudança em $y$ dividida pela mudança em $x$, assim:
$$ b_1 \approx \frac{-10}{8} = -1.25$$

## Análise de Regressão -- Exemplo 1


\small

* Agora os *famosos cinco*


\scriptsize
```{r}
#| tidy: true
#| echo: true
#| eval: true
(SX <- sum(X))
(SSX <- sum((X - mean(X))^2))
(SY <- sum(Y))
(SSY <- sum((Y - mean(Y))^2))
(SSXY <- sum((X - mean(X))*(Y - mean(Y))))
```


\small

* E agora calculamos os parâmetros:


\scriptsize
```{r}
#| tidy: true
#| echo: true
#| eval: true
(b_1 <- SSXY/SSX)
(b_0 <- mean(Y) - b_1*mean(X))
```

## Análise de Regressão -- Exemplo 1

\small


Verificando o ajuste!


\scriptsize
\centering
```{r}
#| tidy: true
#| out-height: 6cm
#| echo: true
#| eval: true
plot(X,Y, pch=21, col='blue',bg="red")
abline(coef=c(b_0,b_1))
```

## Análise de Regressão -- Exemplo 1 ANOVA


\small

* Vamos calcular `SSM`, `RSS` e `MSM` para determinar a estatística $F$.


\scriptsize

:::: {.columns}

::: {.column width="50%"}

```{r}
#| tidy: true
#| out-width: 5cm
#| echo: true
#| eval: true
y_i = b_0 + b_1 * X
(SSM = sum((y_i - mean(Y))^2))
(MSM = SSM/1)
```

:::

::: {.column width="50%"}

```{r}
#| tidy: true
#| out-width: 5cm
#| echo: true
#| eval: true
(RSS = sum((Y - y_i)^2))
(MSE = RSS/(n-2))
(F = MSM/MSE)
```

:::

::::


\small

* Para avaliar o nosso *F* ratio de `r round(F,3)`, vamos comparar com o valor crítico de F, com 1 d.f. no numerador e `r n-2` d.f. no denominador, com 95\% de grau de confiança.


\scriptsize
```{r}
#| tidy: true
#| echo: true
#| eval: true
qf(0.95,1,n-2)
```


\small

* Como nosso $F$ ( `r round(F,3)` $>$ `r round(qf(0.95,1,n-2),3)`) rejeitamos a hipótese nula de que $\beta_1$ seja 0.

## Análise de Regressão -- Exemplo 1

* Ajustando pelo `lm` e verificando o ajuste


\scriptsize
```{r}
#| tidy: true
#| echo: true
#| eval: true
mod <- lm(growth ~ tannin, data=reg.data)
summary(mod)
```


## Análise de Regressão -- Exemplo 1


\small

* Verificando o ajuste -- ANOVA


\scriptsize
```{r}
#| tidy: true
#| echo: true
#| eval: true
mod <- lm(growth ~ tannin, data=reg.data)
anova(mod)
```

\small

* Para avaliar o nosso *F* ratio de 30.974 temos duas maneiras:
    + Comparar com o valor crítico de F, com 1 d.f. no numerador e 7 d.f. no denominador. 
    + vamos usar os quantis do *F* com 95\% com a função `qf` para achar o valor crítico de *F*.


\scriptsize
```{r}
#| tidy: true
#| echo: true
#| eval: true
qf(0.95,1,7)
```


## Análise de Regressão -- Exemplo 1


\small

* Como nosso valor calculado de *F* é muito maior do que este valor crítico, estamos confiantes para rejeitar a hipótese nula:
    + Que a inclinação da reta de regressão é zero.
* A outra maneira, que é talvez melhor do que trabalhar rigidamente em 5\% é perguntar a probabilidade de se obter um valor *F* tão grande como $30.974$ ou maior se a hipótese nula é verdade.
    + Para isso, utilizamos `1-pf` ao invés de `qf`


\footnotesize
```{r}
#| tidy: true
#| echo: true
#| eval: true
1 -pf(30.974, 1, 7)
```

\small

* É bastante improvável na verdade ($p < 0.001$). Este valor é o que está na última coluna da saída do sumário da ANOVA.


## Análise de Regressão -- Exemplo 2


\small

* Podemos ilustrar o efeito da *regressão* utilizando dados de exames de alunos que fizeram um determinado curso de estatística.
    + Os dados estão no Moodle: `stat500.csv`
* Após lermos os dados, fazemos um procedimento chamado *padronização*, que é deixar os dados com média "zero" e desvio padrão "um". 
    + Para isso, utilizamos a função `scale` do R.


\scriptsize
```{r}
#| tidy: true
#| echo: true
#| eval: true
stat500uns <- read.csv("~/docs/cursos/tna5773/datasets/stat500.csv",header=TRUE)
stat500 <- data.frame(scale(stat500uns))
str(stat500)
sapply(stat500,mean)
sapply(stat500,sd)
```

## Análise de Regressão -- Exemplo 2


\small

* Vamos plotar as notas no exame final versus as notas do exame *midterm*
    + Também colocamos uma linha do tipo $y = x$
    

\centering
\scriptsize
```{r}
#| tidy: true
#| out-width: 5cm
#| fig-width: 5
#| echo: true
#| eval: true
plot(final ~ midterm,stat500)
abline(0,1)
```

## Análise de Regressão -- Exemplo 2 


\small

* Vamos calcular o ajuste da regressão por mínimos quadrados e plotar a linha de regressão. Também vamos calcular as correlações.
    
:::: {.columns}

::: {.column width="45%"}

\tiny

```{r}
#| tidy: true
#| echo: true
#| eval: true
g <- lm(final ~ midterm, stat500)
cor(stat500)
```

:::

::: {.column width="50%"}

\tiny
```{r}
#| tidy: true
#| echo: true
#| eval: true
plot(final ~ midterm, stat500)
abline(0,1)
abline(g$coef,lty=5)
```

:::

::::

## Análise de Regressão -- Exemplo 2


* Vemos que para os alunos que tiraram 1 SD acima da média no *midterm*, prevemos que terão uma nota um pouco abaixo que isto na média no exame final (veja a linha tracejada da regressão)
    - $0.54523$ SD acima da média para ser exato.
* Do mesmo modo, um estudante que tirou menos do que a média no *midterm*, é esperado que vá relativamente melhor no exame final, apesar que ainda abaixo da média.
* **Esta é a regressão à mediocridade** que Galton estudou e descreveu, com relação à altura de pais e filhos.
    + Pais altos tendem a ter filhos altos, mas não tão altos quanto seus pais.
    + Pais baixos tendem a ter filhos baixos, mas não tão baixos quanto seus pais.

## Análise de Regressão -- Exemplo 2

* Verificando o ajuste


\scriptsize
```{r}
#| tidy: true
#| echo: true
#| eval: true
summary(g)
```


## Análise de Regressão -- Exemplo 2


\small

* Verificando o ajuste -- ANOVA


\scriptsize
```{r}
#| tidy: true
#| echo: true
#| eval: true
anova(g)
```

## Diagnósticos da Regressão

\small

* Temos utilizado até aqui a função `summary()` para termos os parâmetros do modelo e um sumário das estatísticas.
* Infelizmente, **nada** na saída da função `summary(model)` nos diz se o nosso modelo é apropriado.
    * Ou seja, que satisfizemos as hipóteses estatísticas subjacentes ao nosso modelo.
    * Nossa confiança nas inferências sobre os parâmetros da regressão dependem do grau em que conseguimos atender as hipóteses estatísticas do modelo de **minimos quadrados ordinários** -- **OLS**.
    
* Por que isso é importante?
    * Irregularidades nos dados ou uma especificação errada dos relacionamentos entre as variáveis preditoras e a variável resposta pode nos levar a especificar um modelo amplamente impreciso.
    * Também podemos concluir que uma variável preditora e a variável resposta não estão relacionadas, quando na verdade, estão.
        * Ou o contrário!


## Diagnósticos da Regressão

* O R tem muitos métodos para se avaliar as hipóteses estatísticas em uma análise de regressão.
* A abordagem mais comum é aplicar a função `plot()` ao objeto retornado pela função `lm()`.
* Fazendo isso, teremos quatro gráficos que são úteis para se avaliar o ajuste de modelo.


\footnotesize
```{r}
#| tidy: true
#| eval: false
#| echo: true
#| out-height: 8cm
par(mfrow=c(2,2))
plot(g)
```

---

```{r}
#| tidy: true
#| echo: false
#| eval: true
#| out-height: 7.5cm
par(mfrow=c(2,2))
plot(g)
```

## Gráficos Diagnósticos da Regressão

###  Topo-esquerda

Mostra os resíduos no eixo y contra os valores ajustados no eixo x. Não se deve observar estruturas ou padrões no gráfico. Os pontos devem se parecer como o céu à noite. É um problema se os pontos se espalham conforme os valores ajustados ficam maiores -- como se fosse uma fatia de queijo. A amplitude de variação dos resíduos deve ser independente dos valores ajustados.

### Topo-direita

Gráfico **qqnorm** (normal) que deve ser uma linha reta se
os erros são normalmente distribuídos. Se o gráfico
tivesse a forma de um **S** ou de uma **banana**
precisariamos ajustar um modelo diferente.

## Usando o pacote `lmtest` para avaliar o modelo

Vamos utilizar a função `bptest` que executa o teste de Breusch-Pagan, que ajusta um modelo linear de regressão aos resíduos de um modelo de regressão linear (por _default_ as mesmas variáveis explicativas são utilizadas como no modelo principal de regressão) e rejeita se muito da variância é explicada pelas variáveis explanatórias adicionais.

A hipótese nula do teste é que o modelo tem variância constante, ou seja, é um teste de homocedasticidade do nosso modelo. 


\scriptsize
```{r}
#| warning: false
#| message: false
#| echo: true
#| eval: true
library(lmtest)
```


\scriptsize
```{r}
#| echo: true
#| eval: true
bptest(g)
```

\small 

Como o `p-value` do teste é maior do que 0.05, aceitamos a hipótese nula de que a variância é constante.

## Fazendo uma Regressão Linear manualmente

Um artigo publicado na revista [Technometrics](http://amstat.tandfonline.com/loi/tech), de SC Narula, e JF Wellington (*Prediction, linear regression, and a minimum sum of relative errors*), apresenta dados de preços de vendas e taxas anuais para 24 casas.

#### Dados

Os dados do artigo mencionado estão disponíveis no Moodle: **montgomery_11-4.txt**

Com isso:

- Faça a importação dos dados, verifique sua estrutura e faça um sumário estatístico.
    + Importação
    + Estrutura
    + Sumário

- Faça um gráfico apropriado para relacionar o preço de vendas às taxas pagas (o preço de venda varia conforma as taxas, ou seja, o preço é a variável dependente).



## Ajustando um modelo linear

Como vimos pelas soluções acima, primeiro calculamos $\hat{\beta_1}$, e depois $\hat{\beta_0}$. Para facilitar as contas, vamos criar objetos `X` e `Y` com as colunas `Venda` e `Taxa` (saber quem é `X` e quem é `Y` faz parte da interpretação do problema), e `n` que é o tamanho da amostra

\small
```{r}
#| echo: true
#| eval: true
## Defina X, Y, e n

```

Agora calculamos $\hat{\beta_1}$ com a solução acima

\small
```{r}
#| echo: true
#| eval: true
## Crie um objeto chamado beta1

```

## Ajustando um modelo linear

E $\hat{\beta_0}$ com a solução acima

\small
```{r}
#| echo: true
#| eval: true
## Crie um objeto chamado beta0

```

Para conferir os seus cálculos e prosseguir com a análise, ajuste um modelo linear entre as duas variáveis consideradas, usando a função `lm()`, e verifique se os coeficientes estimados pela função são os mesmos que você calculou à mão.

\small
```{r}
#| echo: true
#| eval: true
## Crie um objeto chamado mod com o modelo ajustado

```


## Análise de Variância

* Um quadro de ANOVA para o modelo irá testar, através de um teste F, se a soma de quadrados do modelo é significativamente diferente de zero. 

* Para fazer essa ANOVA, usamos a função `anova()`

\small
```{r}
#| echo: true
#| eval: true
## Quadro de Análise de Variância

```

## Análise do Ajuste do Modelo de Regressão Linear

* Uma parte importante em uma análise de regressão linear é a verificação dos resíduos do modelo, ou seja, os desvios de cada valor observado $Y$ em relação aos valores **preditos** pelo modelo, $\hat{Y}$. 

* Como vimos que a suposição do modelo é de que os resíduos possuam uma distribuição normal com média 0 e variância constante, $e_i \sim \text{N}(0, \sigma^2)$, então podemos verificar essa suposição fazendo um histograma destes resíduos. 

* Para isso, podemos extrair os resíduos diretamente do objeto `mod` com a função `residuals()`, e fazer o histograma destes resíduos

## Análise do Ajuste do Modelo de Regressão Linear

* Ainda com o objeto `mod`, podemos ajustar o modelo graficamente ao gráfico da relação entre `Venda` e `Taxas`. 

* Para isso, usamos uma função `abline()`, utilizada para inserir linhas em gráficos. 
    +  Faça o gráfico da relação entre Taxa e Vendas, 
    +  Insira a linha do modelo com abline()


## Responda

Com os resultados que você obteve acima, responda:

1. Existe uma relação significativa entre preço de venda e taxas? Se sim, de que tipo (positiva,	negativa)?
2. Pelo resultado da ANOVA, o modelo pode ser considerado significativo (ou seja, uma variável pode ser explicada pela outra)?
3. Através do histograma dos resíduos, pode-se dizer que os pressupostos do modelo foram atendidos (ou seja, os resíduos possuem uma distribuição normal com média em torno do zero)?






<!-- acho que esta parte tá fora de lugar; vou tirar 

## Inferência sobre a média de vendas

* Sabemos que o intervalo de confiança para média de uma distribuição normal com variância desconhecida, para uma amostra de tamanho $n$ é dado por:
$$\left(\bar{x} - t_t \sqrt{\frac{s^2}{n}} \quad, \quad \bar{x} + t_t \sqrt{\frac{s^2}{n}} \right) $$

onde $t_t$ é o quantil de ordem $1-\alpha/2$ da distribuição $t$ de 
Student, com $n-1$ graus de liberdade.

* Considerando que estamos interessados em obter um intervalo de confiança para a média de `Vendas`, faça o que se pede:
    - Calcule o tamanho da amostra, a média e a variância amostral da coluna `Vendas`
    - Monte o intervalo de confiança utilizando os quantis da distribuição $t$, para obter um IC de 95\% de confiança.



## Teste de Hipóteses

* Além do intervalo de confiança, podemos realizar um teste de hipótese para testar se a média de vendas é igual a determinado valor. Os procedimentos gerais para este teste de hipótese são:

1. Definir a hipótese nula ($H_0$) e a alternativa ($H_1$)
2. Definir um nível de **significância** $\alpha$ (ex.: $\alpha =
  0,05$), que irá determinar o nível de **confiança** $100(1-\alpha)\%$
  do teste
3. Determinar a **região de rejeição** com base no nível de
  significância $\rightarrow$ valor crítico
4. Calcular a **estatística de teste**, sob a hipótese nula
$$t_{calc} = \frac{\bar{x} - \mu_0}{s/\sqrt{n}} $$
5. Rejeitar a hipótese nula se a estatística de teste calculada
  estiver dentro da região de rejeição ($|t_{calc}| > |t_{crit}|$)


## Teste de Hipóteses

Portanto, se desejamos testar a hipótese de que o preço médio de venda é igual 35, temos as seguintes hipóteses:
$$
\begin{array}{lll}
\text{H}_0: \mu & = &  35 \\
\text{H}_1: \mu & \neq & 35 \\
\end{array}
$$

* Usando um nível de significância $\alpha = 0,05$, realize este teste de hipótese passo-a-passo, calculando: o valor crítico de $t$, o valor de $t$ calculado, e o p-valor do teste:
    + Valor de alpha
    + Valor crítico de t
    + Estatística de teste
    + $t_{calc} > t_{crit}$?

* Use a função `t.test()` para conferir os cálculos que você realizou acima. 
* Qual a sua conclusão a respeito do teste de hipótese?

-->

