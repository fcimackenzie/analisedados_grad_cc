[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Análise de Dados",
    "section": "",
    "text": "Coleção de textos, slides e exercícios sobre Análise de Dados, Machine Learning e tópicos relacionados."
  },
  {
    "objectID": "exerciciosteoria/organizacaoprobestatistico.html",
    "href": "exerciciosteoria/organizacaoprobestatistico.html",
    "title": "Organização de um problema estatístico",
    "section": "",
    "text": "A maioria de nossos exemplos e exercícios teve por objetivo ajudar você a aprender as ferramentas básicas (gráficos e cálculos) para a descrição e comparação de distribuições. Você aprendeu, também, os princípios básicos que orientam o uso dessas ferramentas, como “comece por um gráfico” e “observe o padrão geral e desvios fortes do padrão”. Os dados com os quais você trabalha não são apenas números; eles descrevem um contexto específico, como a profundidade da água nos Everglades, ou os tempos de viagem para o trabalho. Pelo fato de os dados se originarem de um contexto específico, o passo final no exame de dados é uma conclusão em relação a esse contexto. A profundidade da água nos Everglades tem um ciclo anual que reflete as estações de chuva e de seca na Flórida. Os tempos de viagem para o trabalho são geralmente mais longos em Nova York do que na Carolina do Norte.\nVamos voltar às taxas de graduação no prazo no Ensino Médio, discutidas no Exemplo 1.4. Pelo exemplo, sabemos que as taxas de graduação no prazo variam de 71,1%, no Novo México, a 91%, em Iowa, com mediana de 86%. As taxas de graduação nos estados estão relacionadas a muitos fatores e, em um problema estatístico, em geral tentamos explicar as diferenças ou variação em uma variável como taxa de graduação através de alguns desses fatores. Por exemplo, os estados com menores rendas familiares tendem a ter taxas de graduação mais baixas no Ensino Médio? Ou, os estados em alguma região do país tendem a ter taxas mais baixas de graduação no Ensino Médio do que os estados em outras regiões?\nÀ medida que você aprender mais sobre as ferramentas e os princípios estatísticos, você se deparará com problemas estatísticos mais complexos. Embora nenhum sistema acomode todos os vários problemas que surgem na aplicação da estatística ao mundo real, achamos que o seguinte processo de pensamento em quatro passos dá uma orientação útil. Em particular, o primeiro e o último passos enfatizam que os problemas estatísticos estão ligados a situações específicas do mundo real e, portanto, envolvem mais do que cálculos e desenho de gráficos."
  },
  {
    "objectID": "exerciciosteoria/organizacaoprobestatistico.html#organização-de-um-problema-estatístico-um-processo-de-quatro-passos",
    "href": "exerciciosteoria/organizacaoprobestatistico.html#organização-de-um-problema-estatístico-um-processo-de-quatro-passos",
    "title": "Organização de um problema estatístico",
    "section": "Organização de um problema estatístico: um processo de quatro passos",
    "text": "Organização de um problema estatístico: um processo de quatro passos\n\nESTABELEÇA: Qual é a questão prática, no contexto do mundo real?\nPLANEJE: Quais operações estatísticas específicas esse problema requer?\nRESOLVA: Construa gráficos e faça os cálculos necessários para esse problema.\nCONCLUA: Forneça suas conclusões práticas no contexto do mundo real.\n\nPara ajudar você a dominar o básico, muitos exercícios irão continuar a dizer-lhe o que fazer – faça um histograma, ache o resumo dos cinco números, e assim por diante. Problemas estatísticos reais não vêm com instruções detalhadas. De agora em diante, especialmente nos capítulos finais deste livro, você encontrará alguns exercícios que são mais realistas. Use o processo dos quatro passos como guia para resolver e relatar esses problemas. Estes vêm marcados com o ícone dos quatro passos, como ilustra o exemplo seguinte.\n\nEXEMPLO 2.9 Comparação de taxas de graduação\nESTABELEÇA: A lei federal exige que todos os estados nos EUA usem um cálculo comum para as taxas de graduação no prazo no Ensino Médio, começando no ano escolar de 2010 e 2011. Anteriormente, os estados escolhiam vários métodos de cálculo que davam respostas que podiam variar em mais de 10%. Esse cálculo comum permite comparação significativa das taxas de graduação entre os estados.\nPela Tabela 1, agora sabemos que as taxas de graduação no prazo no Ensino Médio no ano escolar de 2016 e 2017 variaram de 71,1%, no Novo México, a 91%, em Iowa. O birô do censo norte-americano divide os 50 estados e o Distrito de Colúmbia em quatro regiões geográficas: a Nordeste (NE), Meio-Oeste (MO), Sul (S) e Oeste (O). A região para cada estado está incluída na Tabela 1.1. Os estados nas quatro regiões do país apresentam distribuições distintas das taxas de graduação? Como se comparam as taxas médias de graduação dos estados em cada uma dessas regiões?\n\n\n\n\n\n\nTabela 1:  Percentual de alunos do ensino médio que se graduaram no tempo\ncerto \n  \n    \n    \n      Estado\n      Percent.\n      Região\n      Estado\n      Percent.\n      Região\n      Estado\n      Percent.\n      Região\n    \n  \n  \n    Alabama\n86.3\nS\nLouisiana\n74.6\nS\nOhio\n81.8\nMO\n    Alaska\n71.1\nO\nMaine\n86.5\nNE\nOklahoma\n82.7\nS\n    Arizona\n75.7\nO\nMaryland\n86.4\nS\nOregon\n72.0\nO\n    Arkansas\n86.9\nS\nMassachusetts\n86.1\nNE\nPennsylvania\n85.5\nNE\n    California\n81.0\nO\nMichigan\n78.6\nMO\nRhode Island\n80.8\nNE\n    Colorado\n77.3\nO\nMinnesota\n81.2\nMO\nSouth Carolina\n80.1\nS\n    Connecticut\n87.0\nNE\nMississippi\n77.6\nS\nSouth Dakota\n82.7\nMO\n    Delaware\n87.0\nS\nMissouri\n87.3\nMO\nTennessee\n87.2\nS\n    Florida\n76.1\nS\nMontana\n85.4\nO\nTexas\n88.3\nS\n    Georgia\n72.5\nS\nNebraska\n89.7\nMO\nUtah\n83.9\nO\n    Hawaii\n81.8\nO\nNevada\n70.0\nO\nVermont\n87.8\nNE\n    Idaho\n77.3\nO\nNew Hampshire\n88.1\nNE\nVirginia\n85.3\nS\n    Illinois\n86.0\nMO\nNew Jersey\n88.6\nNE\nWashington\n78.2\nO\n    Indiana\n87.9\nMO\nNew Mexico\n68.5\nO\nWest Virginia\n84.5\nS\n    Iowa\n90.5\nMO\nNew York\n77.8\nNE\nWisconsin\n88.6\nMO\n    Kansas\n85.7\nMO\nNorth Carolina\n83.9\nS\nWyoming\n78.6\nO\n    Kentucky\n87.5\nS\nNorth Dakota\n87.2\nMO\nDistrict of Columbia\n61.4\nS\n  \n  \n  \n\n\n\n\n\nPLANEJE: Use gráficos e resumos numéricos para descrever e comparar as distribuições das taxas de graduação no prazo no Ensino Médio dos estados nas quatro regiões dos EUA.\nRESOLVA: Podemos usar diagramas em caixa para comparar as distribuições, mas diagramas de ramo e folhas preservam mais detalhes e funcionam bem com conjuntos de dados desse tamanho. Abaixo são apresentados diagramas de ramo e folhas com os ramos alinhados, para fácil comparação. Os ramos foram divididos para apresentar melhor as distribuições, e os dados foram arredondados para o percentual mais próximo (sem casas decimais). Os diagramas de ramo e folhas se sobrepõem, e é necessário algum cuidado na comparação dos quatro diagramas de ramo e folhas porque os tamanhos amostrais diferem, com alguns diagramas de ramo e folhas tendo mais folhas do que outros. Os estados norte-americanos do Nordeste e do Meio-Oeste têm distribuições que são semelhantes entre si. O Sul, com a maioria das observações, tem uma observação baixa que corresponde ao Distrito de Colúmbia, que fica um pouco separado dos demais, e alguma assimetria à esquerda. Com pouca assimetria e sem valores atípicos sérios, relatamos x e s como nossas medidas resumo do centro e variabilidade da distribuição das taxas de graduação no prazo dos estados em cada região. Como o Distrito de Colúmbia não é um estado, embora frequentemente incluído com dados dos estados, relatamos as estatísticas resumo para o Sul com e sem essa observação.\n\n\n\n\n\n\n  \n    \n    \n      Região\n      N\n      Média\n      Desvio Padrão\n    \n  \n  \n    Meio-Oeste\n12\n85.60\n3.72\n    Nordeste\n9\n85.36\n3.65\n    O\n13\n76.98\n5.36\n    Sul (inc. DC)\n17\n81.66\n7.20\n    Sul (exc. DC)\n16\n82.93\n5.13\n  \n  \n  \n\n\n\n\n\n\nDiagramas Ramo-Folha para as Regiões\n\n\nOeste\n\n\n\n\n\n\nNordeste\n\n\n\n\n\n\n\n\n\nSul\n\n\n\n\n\n\nMeio-Oeste\n\n\n\n\n\n\n\nCONCLUA: A tabela de estatísticas resumo e os diagramas de ramo e folhas levam a conclusões semelhantes. Os estados norte-americanos do Meio-Oeste e do Nordeste são mais semelhantes entre si com o Sul, excluindo o Distrito de Colúmbia, tendo uma média ligeiramente menor e maior desvio-padrão. Os estados do Oeste têm uma taxa média de graduação mais baixa do que as outras três regiões, com desvio-padrão semelhante ao do Sul, porém mais alto do que os do Meio-Oeste ou Nordeste.\nÉ importante lembrar que os indivíduos no Exemplo 2.9 são os estados. Por exemplo, a média de 87,12 é a média das taxas de graduação no prazo para os nove estados norte-americanos do Nordeste, e o desvio-padrão nos diz quanto as taxas desses estados variam em relação a essa média. No entanto, a média desses nove estados não é a mesma que a taxa de graduação para todos das escolas de Ensino Médio no Nordeste, a menos que os estados tenham o mesmo número de graduados no Ensino Médio. A taxa de graduação no Nordeste para todos os estudantes do Ensino Médio no Nordeste é uma média ponderada das taxas dos estados, com os maiores estados recebendo mais peso. Por exemplo, como Nova York é o estado mais populoso no Nordeste e tem também a menor taxa da graduação, esperaríamos que a taxa de graduação de todos os estudantes do Ensino Médio no Nordeste fosse menor que 87,12, porque Nova York puxaria para baixo a taxa geral de graduação. Um exemplo análogo pode ser observado no Exercício 2.371"
  },
  {
    "objectID": "exerciciosteoria/organizacaoprobestatistico.html#footnotes",
    "href": "exerciciosteoria/organizacaoprobestatistico.html#footnotes",
    "title": "Organização de um problema estatístico",
    "section": "Notas de rodapé",
    "text": "Notas de rodapé\n\n\nReferente ao livro texto.↩︎"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Sobre",
    "section": "",
    "text": "Coleção de textos, slides e exercícios sobre Análise de Dados, Machine Learning e tópicos relacionados.\nUma tentativa de construir um repositório organizado para os diversos materiais que já preparei para disciplinas muito parecidas em diversas instituições, épocas e formatos diferentes."
  },
  {
    "objectID": "exerciciosteoria/diagramasdispersaocorrelacao.html",
    "href": "exerciciosteoria/diagramasdispersaocorrelacao.html",
    "title": "Exercícios Diagramas Dispersão e Correlação",
    "section": "",
    "text": "Homicídio e suicídio. A prevenção do suicídio é um problema importante encarado pelos trabalhadores da saúde mental. A previsão de regiões geográficas onde o risco de suicídio é alto poderia ajudar as pessoas a decidir onde aumentar ou melhorar os recursos e cuidados com a saúde. Alguns psiquiatras argumentaram que homicídio e suicídio podem ter algumas causas em comum. Nesse caso, seria de se esperar que as taxas de homicídio e suicídio fossem correlacionadas. E se isso é verdade, áreas com altas taxas de homicídio poderiam ter previsão de altas taxas de suicídio e, portanto, merecedoras de mais recursos para a saúde mental. A pesquisa tem tido resultados mistos, incluindo alguma evidência de que há uma correlação positiva em certos países europeus, mas não nos EUA. Eis os dados de 2015 para 11 condados em Ohio com dados suficientes para homicídios e suicídios para permitir uma estimativa de taxas para ambos. As taxas são por 100 mil pessoas.\n\n\n\n\n\n\n\n  \n    \n    \n      Condado\n      Taxa de homicídio\n      Taxa de suicídio\n    \n  \n  \n    Butler\n4.0\n11.2\n    Clark\n10.8\n15.3\n    Cuyahoga\n12.2\n11.4\n    Franklin\n8.7\n12.3\n    Hamilton\n10.2\n11.0\n    Lorain\n3.3\n14.3\n    Lucas\n6.0\n12.6\n    Mahoning\n11.7\n15.2\n    Montgomery\n8.9\n15.7\n    Stark\n5.8\n16.1\n    Summit\n7.1\n17.9\n  \n  \n  \n\n\n\n\n\nPerguntaResposta\n\n\nFaça um diagrama de dispersão para verificar se taxas de homicídio e suicídio são correlacionadas. Para esses dados, estamos simplesmente interessados em explorar a relação entre as duas variáveis, de modo que nenhuma variável é uma escolha óbvia para a variável explicativa. Por conveniência, use a taxa de homicídio como variável explicativa e taxa de suicídio como resposta.\n\n\n\n\nCódigo\nggplot(homicidiosuicidio) +\n  geom_point(aes(x=`Taxa de homicídio`, y = `Taxa de suicídio`)) +\n  scale_x_continuous(limits = c(0,15)) +\n  scale_y_continuous(limits = c(0,20)) +\n  theme_light()\n\n\n\n\n\n\n\n\n\nTerceirização pelas companhias aéreas. As companhias aéreas têm terceirizado, de modo crescente, a manutenção de suas aeronaves para outras companhias. Uma preocupação externada por críticos é que a manutenção pode ser feita de maneira menos cuidadosa, de modo que a terceirização cria uma condição de perigo. Além disso, os atrasos são constantes, devido a problemas de manutenção, de modo que se devem examinar os dados do governo sobre percentuais das principais manutenções terceirizadas e percentuais de atrasos em voos atribuídos à companhia, para determinar se a preocupação se justifica. Isso foi feito e os dados de 2005 e 2006 parecem justificar a preocupação dos críticos. Dados mais recentes justificam essa preocupação? Eis os dados para 2018.\n\n\n\n\n\n\n\n  \n    \n    \n      Companhia\n      Percentual Terceirização\n      Percentual Atraso\n    \n  \n  \n    Alaska\n62.8\n14\n    Allegiant\n8.0\n22\n    American\n38.8\n20\n    Delta\n53.7\n15\n    Frontier\n39.1\n31\n    Hawaiian\n75.5\n8\n    JetBlue\n71.0\n19\n    Southwest\n53.6\n24\n    Spirit\n20.9\n18\n    United\n52.0\n18\n  \n  \n  \n\n\n\n\n\nPerguntaResposta\n\n\nFaça um diagrama de dispersão que mostre a relação entre atrasos e terceirização\n\n\n\n\nCódigo\nterceirizacao %&gt;%\n  ggplot() +\n  geom_point(aes(x = `Percentual Terceirização`, y = `Percentual Atraso`)) +\n  scale_x_continuous(limits = c(0,80)) +\n  scale_y_continuous(limits = c(0,35)) +\n  theme_light()\n\n\n\n\n\n\n\n\n\nDirigir rápido desperdiça gasolina? Como muda o consumo de gasolina de um carro quando sua velocidade aumenta? A seguir, estão os dados para um Volkawagen Jetta Diesel de 2013. A velocidade foi medida em milhas por hora, e o consumo de combustível, em milhas por galão.\n\n\n\n\n\n\n\n  \n    \n    \n      Velocidade\n      Consumo\n    \n  \n  \n    20\n49.0\n    30\n67.9\n    40\n66.5\n    50\n59.0\n    60\n50.4\n    70\n44.8\n    80\n39.1\n  \n  \n  \n\n\n\n\n\nPerguntaResposta\n\n\n\nFaça um diagrama de dispersão. (Qual é a variável explicativa?)\nDescreva a forma da relação. Ela não é linear. Explique por que a forma da relação faz sentido.\nNão faz sentido descrever as variáveis como positivamente associadas ou negativamente associadas. Por quê?\nA relação é razoavelmente forte ou bem fraca? Explique sua resposta.\n\n\n\n\nFaça um diagrama de dispersão. (Qual é a variável explicativa?)\n\nA variável explicativa é Velocidade, porque queremos saber como o Consumo de combustível varia conforme variamos a Velocidade.\n\n\nCódigo\nconsumo_x_velocidade %&gt;%\n  ggplot() +\n  geom_point(aes(x=Velocidade,y=Consumo)) +\n  scale_x_continuous(limits = c(0,85)) +\n  scale_y_continuous(limits = c(0,85)) +\n  theme_light()\n\n\n\n\n\n\nA relação não é linear; uma possível explicação é porque os veículos são mais eficientes em termos de consumo em velocidades mais altas (pelo menos até certo limite de velocidade).\nComo o gráfico apresenta uma relação não linear, não faz sentido indicar se a relação é positiva ou negativa para todos os pontos; aparentemente, entretanto, podemos dizer que para velocidades de até 30mph, temos uma relação positiva e a partir de 30mph temos uma relação negativa.\n\n\n\nCódigo\nggplot(consumo_x_velocidade) +\n  geom_point(data=filter(consumo_x_velocidade,Velocidade &lt;= 30), aes(x = Velocidade, y=Consumo), color =\"red\") +\n  geom_point(data=filter(consumo_x_velocidade,Velocidade &gt; 30), aes(x = Velocidade, y=Consumo), color =\"blue\") +\n  scale_x_continuous(limits = c(0,85)) +\n  scale_y_continuous(limits = c(0,85)) +\n  theme_light()\n\n\n\n\n\n\nConsiderando a primeira parte dos dados, até 30mph, temos uma relação positiva forte; para os dados a partir de 30mph, a relação é positiva, mas de menor intensidade.\n\n\n\n\n\nRecifes de coral. Considere um estudo feito por cientistas, que examinaram dados sobre as temperaturas médias da superfície do mar (em graus Celsius) e o crescimento médio de corais (em centímetros por ano), durante um período de vários anos, em localizações do Golfo do México e do Caribe. Eis os dados para o Golfo do México:\n\n\n\n\n\n\n\n  \n    \n    \n      Temperatura Superf. Mar\n      Crescimento\n    \n  \n  \n    26.7\n0.85\n    26.6\n0.85\n    26.6\n0.79\n    26.5\n0.86\n    26.3\n0.89\n    26.1\n0.92\n  \n  \n  \n\n\n\n\n\nPerguntaResposta\n\n\n\nFaça um diagrama de dispersão. Qual é a variável explicativa? O gráfico mostra um padrão linear negativo.\nEncontre a correlação r passo a passo. Você pode querer arredondar os dados para duas casas decimais em cada passo. Primeiro, encontre a média e o desvio-padrão de cada variável. Determine, então, os seis valores padronizados para cada variável. Finalmente, use a fórmula de r. Explique como seu valor para r coincide com a direção do padrão linear em seu gráfico da parte (a).\nDigite, agora, esses dados em sua calculadora ou em um software e use a função correlação para encontrar r. Verifique se você obteve o mesmo resultado que em (b), a menos de erros de arredondamento.\n\n\n\n\nFaça um diagrama de dispersão.\n\n\n\nCódigo\ntempgolfmexico %&gt;%\n  ggplot() +\n  geom_point(aes(x=`Temperatura Superf. Mar`,y=Crescimento)) +\n  scale_x_continuous(limits = c(26,27)) +\n  scale_y_continuous(limits = c(0.7,1)) +\n  theme_light()\n\n\n\n\n\nA variável explicativa é a Temperatura da Superfície do Mar, já que o estudo visa entender sua influência sobre o Crescimento dos corais. Pelo gráfico temos um padrão aproximadamente linear negativo.\n\nEncontre a correlação r passo a passo.\n\nDesvio Padrão de cada variável:\n\n\n\n\n\n\n  \n    \n    \n      TemperaturaSuperf. Mar\n      Crescimento\n      xi - x̅\n      yi - y̅\n      (xi - x̅)2\n      (yi - y̅)2\n    \n  \n  \n    26.7\n0.85\n 0.233\n−0.01\n0.054\n1.000 × 10−4\n    26.6\n0.85\n 0.133\n−0.01\n0.018\n1.000 × 10−4\n    26.6\n0.79\n 0.133\n−0.07\n0.018\n0.005\n    26.5\n0.86\n 0.033\n 0   \n0.001\n0\n    26.3\n0.89\n−0.167\n 0.03\n0.028\n9.000 × 10−4\n    26.1\n0.92\n−0.367\n 0.06\n0.134\n0.004\n  \n  \n  \n\n\n\n\nCom os valores de xi-xbar e de yi-ybar e os respectivos quadrados, podemos calcular os desvios padrões, dado pela fórmula \\[s = \\sqrt{\\frac{1}{n-1}\\sum((x_i - \\bar{x})^2)}\\]\nConsiderando n como 6:\n\nPrimeiro, a soma dos quadrados \\((x_i - \\bar{x})^2\\): 0.2533333; dividindo por \\(n-1\\): 0.050667; restando então, extrair a raiz quadrada.\nDepois, a soma dos quadrados \\((y_i = \\bar{y})^2\\): 0.0096; dividindo por \\(n-1\\): 0.00192; restando então, extrair a raiz quadrada.\nO desvio padrão da Temperatura da Superfície do Mar é então \\(s_{temp}\\) = 0.2251; o cálculo pelo R resulta em 0.2250926.\nO desvio padrão do Crescimento é \\(s_{cresc}\\) = 0.0438; o cálculo pelo R resulta em 0.0438178.\n\nAgora vamos calcular os produtos \\[\\left(\\frac{x_i - \\bar{x}}{s_x}\\right)\\left(\\frac{y_i - \\bar{y}}{s_y}\\right)\\] Para facilitar, vamos adicionar mais três colunas na tabela:\n\n\n\n\n\n\n  \n    \n    \n      TemperaturaSuperf. Mar\n      Crescimento\n      xi - x̅\n      yi - y̅\n      (xi - x̅)2\n      (yi - y̅)2\n      (xi - x̅)/sx\n      (yi - y̅)/sy\n      Produto\n    \n  \n  \n    26.7\n0.85\n 0.233\n−0.01\n0.054\n1.000 × 10−4\n 1.037\n−0.228\n−0.237\n    26.6\n0.85\n 0.133\n−0.01\n0.018\n1.000 × 10−4\n 0.592\n−0.228\n−0.135\n    26.6\n0.79\n 0.133\n−0.07\n0.018\n0.005\n 0.592\n−1.598\n−0.946\n    26.5\n0.86\n 0.033\n 0   \n0.001\n0\n 0.148\n 0    \n 0    \n    26.3\n0.89\n−0.167\n 0.03\n0.028\n9.000 × 10−4\n−0.74 \n 0.685\n−0.507\n    26.1\n0.92\n−0.367\n 0.06\n0.134\n0.004\n−1.629\n 1.369\n−2.231\n  \n  \n  \n\n\n\n\nFazemos então a soma da coluna “Produto” = -4.0555355, e dividimos por \\(n-1\\), o que dá r = -0.8111071\n\nCalculando pelo R, utilizamos a seguinte expressão\n\ncor(tempgolfmexico$`Temperatura Superf. Mar`,tempgolfmexico$Crescimento)\n\n\nCódigo\ncor(tempgolfmexico$`Temperatura Superf. Mar`,tempgolfmexico$Crescimento)\n[1] -0.8111071\n\n\nOs valores coincidem, dentro dos erros de arredondamento.\n\n\n\n\nAquecimento global. As temperaturas médias globais têm aumentado nos anos recentes? Aqui estão as temperaturas médias globais anuais para os últimos 25 anos, em graus Celsius:\n\n\n\n\n\n\n\n  \n    \n    \n      Ano\n      Temperatura\n    \n  \n  \n    1994\n14.25\n    1995\n14.37\n    1996\n14.23\n    1997\n14.42\n    1998\n14.56\n    1999\n14.34\n    2000\n14.33\n    2001\n14.47\n    2002\n14.52\n    2003\n14.54\n    2004\n14.49\n    2005\n14.57\n    2006\n14.54\n    2007\n14.52\n    2008\n14.45\n    2009\n14.55\n    2010\n14.63\n    2011\n14.48\n    2012\n14.54\n    2013\n14.58\n    2014\n14.64\n    2015\n14.83\n    2016\n14.90\n    2017\n14.81\n    2018\n14.73\n  \n  \n  \n\n\n\n\n\nPerguntaResposta\n\n\nDiscuta o que os dados mostram sobre a mudança nas temperaturas médias globais ao longo do tempo\n\n\nEstabeleça: A questão deste problema é examinar a mudança nas temperaturas médias globais no período dado.\nPlaneje: Como temos dados anuais, de 1994 a 2018, podemos criar um gráfico de dispersão para essa visualização.\nResolva:\n\n\nCódigo\naquecglobal %&gt;%\n  ggplot(aes(x = Ano, y = Temperatura)) +\n  geom_point() + \n  geom_smooth(method = lm, se = FALSE) +\n  theme_light()\n\n\n\n\n\nConclua: Como podemos ver do gráfico acima, há uma clara tendência de crescimento das temperaturas médias globais. A linha azul é uma linha de regressão apenas para facilitar a visualização da correlação positiva de intensidade moderada entre Ano e Temperatura.\n\n\nCódigo\ntempinic &lt;- aquecglobal[which(aquecglobal == min(aquecglobal$Ano)),\"Temperatura\"]\ntempfinal &lt;- aquecglobal[which(aquecglobal == max(aquecglobal$Ano)),\"Temperatura\"]\ndeltatemp &lt;- round(((tempfinal - tempinic)/tempinic)*100,2)\ntempmin &lt;- min(aquecglobal$Temperatura)\ntempmax &lt;- max(aquecglobal$Temperatura)\ndeltatemp2 &lt;- round(((tempmax - tempmin)/tempmin)*100,2)\n\n\nEntretanto, precisamos tomar cuidado com a maneira como fazemos gráficos; no exemplo acima, a escala em y não começa em zero, e a amplitude dos dados é muito pequena: 0.67.\nSe considerarmos o valor da temperatura para o ano inicial (1994=14.25) e ano final (2018=14.73), o aumento percentual de temperatura para esse período é de 3.37%.\nSe considerarmos o valor mínimo (14.23) e máximo (14.9) da temperatura durante este período, o aumento percentual de temperatura é de 4.71%."
  },
  {
    "objectID": "exerciciosteoria/lista_exercicios1.html",
    "href": "exerciciosteoria/lista_exercicios1.html",
    "title": "Lista de Exercícios",
    "section": "",
    "text": "Economia de combustível. Eis uma pequena parte de um conjunto de dados que descreve a economia de combustível (em milhas por galão – mpg) para modelos de automóveis de 2019:  O custo anual do combustível é uma estimativa supondo-se 15 mil milhas de rodagem por ano (55% na cidade e 45% na estrada) e um preço médio do combustível:\n\nQuais são os indivíduos nesse conjunto de dados?\nPara cada indivíduo, quais variáveis são fornecidas? Quais delas são categóricas e quais são quantitativas? Em quais unidades são medidas as variáveis quantitativas?\n\nQuais plataformas de áudio os americanos de 12 a 34 anos ouvem? A Pesquisa Edison perguntou qual das várias plataformas de áudio as pessoas nessa faixa etária ouvem. Eis as porcentagens por plataforma. Faça um gráfico de barras para representar esses resultados. Explique porque não podemos fazer um gráfico de setores (pizza).\n\n\n\n\n\n\n\n\n\nPlataforma\nPorcentagem de pessoas de 12 a 34 anos que ouviram cada plataforma\n\n\n\n\nPandora\n36\n\n\nSpotify\n46\n\n\niHeartRadio\n14\n\n\nApple Music\n20\n\n\nAmazonMusic\n10\n\n\nSoundCloud\n23\n\n\nGoogle Play\n8\n\n\n\n\nPor uma pequena margem, Facebook permanece a escolha principal de mídia social em todas as idades, com 29% usando o Facebook com mais frequência entre os que usam mídias sociais. No entanto, as redes sociais mais visualmente orientadas, como Snapchat e Instagram, continuam a penetrar nas audiências mais jovens. Quando se pergunta “Qual plataforma de rede social você usa com mais frequência?”, eis as plataformas mais usadas pelos americanos de 12 a 34 anos que usam atualmente algum serviço ou site de rede social:\n\nQual é a soma das porcentagens para esses sites principais de mídias sociais? Qual o percentual de americanos com idade de 12 a 34 anos que usam outros sites de mídia social com mais frequência?\nFaça um gráfico de barras para apresentar esses dados. Certifique-se de incluir uma categoria “Outra plataforma de mídia social”.\nSeria correto apresentar esses dados em um gráfico de setores? Por que ou por que não?\nOs dados são coletados para responder a questões do mundo real. Quais questões poderiam ser respondidas por esses dados?\n\n\n\n\nA pesquisa com calouros do órgão norte-americano Higher Education Research Institute inclui mais de 120 mil calouros de tempo integral que entraram pela primeira vez em uma faculdade em 2017.4 A pesquisa relata os seguintes dados sobre as fontes que os estudantes usam para pagar as despesas da faculdade: \n\nExplique por que não é correto usar um gráfico de setores para a apresentação desses dados.\nFaça um gráfico de barras dos dados. Observe que, como os dados contrapõem grupos como recursos de família e recursos do estudante, é melhor manter essas barras próximas umas das outras, em vez de ordenar as barras por altura.\n\nNascimentos não são, como você poderia pensar, uniformemente distribuídos ao longo dos dias da semana. Os números médios de bebês nascidos em cada dia da semana, em 2017, são:  Apresente esses dados em um gráfico de barras devidamente rotulado. Também seria correto utilizar um gráfico de setores?\nExplique a diferença entre um histograma e um gráfico de barras. \nA figura abaixo apresenta um histograma dos escores de vocabulário de 947 alunos da sétima série nas escolas públicas de Gary, Indiana, na parte de vocabulário do teste de Iowa de habilidades básicas. Analise esse histograma observando sua forma, o centro, a variabilidade e a presença ou não de valores atípicos.  \nA doença de Lyme é causada por uma bactéria chamada Borrelia burgdorferi e se espalha com a picada de um carrapato de patas pretas infectado, geralmente encontrado em florestas e em áreas relvadas. Houve 383.846 casos confirmados relatados aos Centers for Disease Control and Prevention (CDC) (Centros para Controle e Prevenção de Doenças) entre 2001 e 2017, e esses casos são divididos por idade e sexo na Figura abaixo:  Eis como a Figura acima se relaciona com o que estamos estudando. Os indivíduos são as 383.846 pessoas com casos confirmados, e duas das variáveis medidas em cada indivíduo são sexo e idade. Considerando homens e mulheres separadamente, poderíamos fazer um histograma da variável idade usando intervalos de classe 0 a &lt; 5 anos, 5 a &lt; 10 anos, e assim por diante. Observe as duas barras mais à esquerda na Figura acima. As barras mais escuras mostram que quase 10 mil dos homens estavam entre 0 e 5 anos, e a barra mais clara mostra ligeiramente menos mulheres nessa faixa de idade. Se colocássemos todas as barras mais escuras lado a lado, teríamos o histograma de idade para homens usando os intervalos de classe estabelecidos. Analogamente, as barras mais clara mostram as mulheres. Como estamos tentando apresentar ambos os histogramas no mesmo gráfico, as barras para homens e mulheres dentro de cada classe foram colocadas uma ao lado da outra para uma comparação fácil, com as barras para diferentes intervalos de classe separadas por pequenos espaços.\n\nDescreva as principais características da distribuição de idade para os homens. Por que a descrição dessa distribuição em termos apenas do centro e da variabilidade seria enganosa?\nSuponha que os diferentes grupos de idade de homens gastem diferentes quantidades de tempo ao ar livre. Como esse fato poderia ser usado para explicar o que você encontrou na parte (a)? Lembre-se de usar seus olhos para descrever o padrão que você vê e, então, explique-o.\nUm amigo seu, homem de 45 anos de idade, olha o histograma e lhe diz que ele está planejando desistir de uma caminhada porque esse gráfico sugere que ele está em um grupo de alto risco para a doença de Lyme. Ele retomará a caminhada quando tiver 65 anos, pois será menos provável pegar a doença nessa idade. Essa é uma interpretação correta do histograma?\nComparando os histogramas para homens e mulheres, como eles se assemelham? Qual é a principal diferença, e por que você acha que ela ocorre?\n\nExplique o que é um diagrama de ramo e folhas e a principal diferença para um histograma. Indique também limitações no seu uso.\nExercícios ao final de cada capítulo são muito bons; não faz sentido repeti-los aqui."
  },
  {
    "objectID": "textos/DiagnosticoHipotesesMetodoMinimosQuadrados.html",
    "href": "textos/DiagnosticoHipotesesMetodoMinimosQuadrados.html",
    "title": "Análise de Modelos de Regressão Linear",
    "section": "",
    "text": "como as variáveis que utilizaremos não precisam de ajustes, vamos direto ao modelo\nCall:\nlm(formula = price ~ horsepower + length + engine.size + city.mpg, \n    data = autos)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-9697.0 -1745.7    24.9  1389.4 12904.6 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -28480.00    7114.51  -4.003 8.99e-05 ***\nhorsepower      52.74      16.62   3.174 0.001756 ** \nlength         114.58      32.30   3.548 0.000491 ***\nengine.size    115.32      12.92   8.922 4.06e-16 ***\ncity.mpg        61.51      83.05   0.741 0.459849    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3499 on 188 degrees of freedom\nMultiple R-squared:  0.8168,    Adjusted R-squared:  0.8129 \nF-statistic: 209.5 on 4 and 188 DF,  p-value: &lt; 2.2e-16\nA variável city.mpg não tem significância estatística no nosso modelo, então vamos removê-la e atualizar o modelo.\nCall:\nlm(formula = price ~ horsepower + length + engine.size, data = autos)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-9351.8 -1808.5    87.3  1351.9 13043.5 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -24227.12    4195.20  -5.775 3.12e-08 ***\nhorsepower      44.60      12.44   3.585 0.000429 ***\nlength         102.48      27.83   3.683 0.000301 ***\nengine.size    117.33      12.62   9.296  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3495 on 189 degrees of freedom\nMultiple R-squared:  0.8162,    Adjusted R-squared:  0.8133 \nF-statistic: 279.8 on 3 and 189 DF,  p-value: &lt; 2.2e-16\nAgora todas as variáveis tem significância estatística, e nosso modelo consegue explicar aproximadamente 81.3% da variabilidade da variável alvo, price.\nPróxima etapa, os gráficos diagnósticos.\nFigure 1: Gráficos Diagnósticos\nOs gráficos diagnósticos não estão tão fáceis de interpretar; então podemos utilizar pacotes do R específicos para isso. Um destes pacotes é o lmtest."
  },
  {
    "objectID": "textos/DiagnosticoHipotesesMetodoMinimosQuadrados.html#usando-o-pacote-lmtest-para-avaliar-o-modelo",
    "href": "textos/DiagnosticoHipotesesMetodoMinimosQuadrados.html#usando-o-pacote-lmtest-para-avaliar-o-modelo",
    "title": "Análise de Modelos de Regressão Linear",
    "section": "Usando o pacote lmtest para avaliar o modelo",
    "text": "Usando o pacote lmtest para avaliar o modelo\nVamos utilizar a função bptest que executa o teste de Breusch-Pagan, que ajusta um modelo linear de regressão aos resíduos de um modelo de regressão linear (por default as mesmas variáveis explicativas são utilizadas como no modelo principal de regressão) e rejeita se muito da variância é explicada pelas variáveis explanatórias adicionais.\nA hipótese nula do teste é que o modelo tem variância constante, ou seja, é um teste de homocedasticidade do nosso modelo.\n\n\n    studentized Breusch-Pagan test\n\ndata:  modtr05p1a\nBP = 67.363, df = 3, p-value = 1.566e-14\n\nPor este teste, temos que rejeitar a hipótese nula de que o modelo tem variância constante."
  },
  {
    "objectID": "textos/DiagnosticoHipotesesMetodoMinimosQuadrados.html#usando-o-pacote-olsrr",
    "href": "textos/DiagnosticoHipotesesMetodoMinimosQuadrados.html#usando-o-pacote-olsrr",
    "title": "Análise de Modelos de Regressão Linear",
    "section": "Usando o pacote olsrr",
    "text": "Usando o pacote olsrr\nO pacote olsrr oferece algumas ferramentas para detectar violações das hipóteses padrão da regressão. Vamos examinar apenas algumas funcionalidades, neste caso, o diagnóstico dos resíduos. As hipóteses padrão da regressão incluem as seguintes premissas sobre os resíduos/erros:\n\nO erro tem uma distribuição normal (hipótese de normalidade)\nO erro tem média zero.\nOs erros tem variância constante (mas desconhecida) – hipótese de homocedasticidade.\nOs erros são independentes uns dos outros (hipótese de erros independentes).\n\n\nTestes para detectar a violação da hipótese de normalidade\n\n-----------------------------------------------\n       Test             Statistic       pvalue  \n-----------------------------------------------\nShapiro-Wilk              0.9625          1e-04 \nKolmogorov-Smirnov        0.1023         0.0353 \nCramer-von Mises         16.1468         0.0000 \nAnderson-Darling          2.5759         0.0000 \n-----------------------------------------------\n\nPelos resultados dos testes acima, todos os p-values estão na região de rejeição da hipótese nula, ou seja, os resíduos não seguem uma distribuição normal."
  },
  {
    "objectID": "textos/DiagnosticoHipotesesMetodoMinimosQuadrados.html#usando-o-pacote-gvlma",
    "href": "textos/DiagnosticoHipotesesMetodoMinimosQuadrados.html#usando-o-pacote-gvlma",
    "title": "Análise de Modelos de Regressão Linear",
    "section": "Usando o pacote gvlma",
    "text": "Usando o pacote gvlma\nO pacote gvlma é uma implementação do artigo de Pena & Slate called “Global Validation of Linear Model Assumptions” e nos permite verificar rapidamente por:\n\nLinearidade – o teste Global Stat testa a hipótese nula de que nosso modelo é uma combinação linear das preditoras.\nHeterocedasticidade – o teste correspondente testa a hipótese nula de que a variância dos nossos resíduos é relativamente constante.\nNormalidade – testa distorções na distribuição dos resíduos ( skewness e curtose ), para entendermos se os resíduos do modelo seguem uma distribuição normal. Se a hipótese nula é rejeitada, provavelmente é necessária uma transformação nos dados (p.explo, uma transformação log). Podemos observar isso visualmente no QQ-Plot.\nLink Function – testa se nossa variável dependente é realmente contínua, ou categórica. Se a hipótese nula é rejeitada (p-value &lt; 0.05), é uma indicação de que deveríamos utilizar uma forma alternativa do modelo linear generalizado (p.explo, Regressão Logística ou Binomial, etc).\n\n\n\nCall:\nlm(formula = price ~ horsepower + length + engine.size, data = autos)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-9351.8 -1808.5    87.3  1351.9 13043.5 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -24227.12    4195.20  -5.775 3.12e-08 ***\nhorsepower      44.60      12.44   3.585 0.000429 ***\nlength         102.48      27.83   3.683 0.000301 ***\nengine.size    117.33      12.62   9.296  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3495 on 189 degrees of freedom\nMultiple R-squared:  0.8162,    Adjusted R-squared:  0.8133 \nF-statistic: 279.8 on 3 and 189 DF,  p-value: &lt; 2.2e-16\n\n\nASSESSMENT OF THE LINEAR MODEL ASSUMPTIONS\nUSING THE GLOBAL TEST ON 4 DEGREES-OF-FREEDOM:\nLevel of Significance =  0.05 \n\nCall:\n gvlma(x = modtr05p1a) \n\n                    Value   p-value                   Decision\nGlobal Stat        30.770 3.411e-06 Assumptions NOT satisfied!\nSkewness            4.062 4.387e-02 Assumptions NOT satisfied!\nKurtosis           22.457 2.150e-06 Assumptions NOT satisfied!\nLink Function       2.244 1.342e-01    Assumptions acceptable.\nHeteroscedasticity  2.008 1.565e-01    Assumptions acceptable.\n\nComo vemos do teste acima, nosso modelo passa no teste de Heterocedasticidade e da Função Link (nossa variável resposta é contínua), mas falha na normalidade dos resíduos e na combinação linear das preditoras.\nÀs vezes, o modelo pode ser melhorado removendo-se pontos indicados como outliers, ou seja, primeiro faz-se uma limpeza dos dados e então cria-se um novo modelo. Muitas vezes, a remoção de outliers é suficiente para fazer com que o modelo passe nos testes. Os outliers que vamos remover estão indicados no gráfico QQ-plot na Figura Figure 1.\n\n\nCall:\nlm(formula = price ~ horsepower + length + engine.size, data = autos[-c(120, \n    16, 46), ])\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-9023.6 -1732.9   127.2  1488.0  9605.7 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -24194.83    3914.71  -6.180 3.95e-09 ***\nhorsepower      34.15      11.63   2.936 0.003748 ** \nlength         102.25      26.36   3.879 0.000146 ***\nengine.size    125.15      11.90  10.515  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3195 on 186 degrees of freedom\nMultiple R-squared:  0.822, Adjusted R-squared:  0.8191 \nF-statistic: 286.3 on 3 and 186 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\n\n\n\nCall:\nlm(formula = price ~ horsepower + length + engine.size, data = autos[-c(120, \n    16, 46), ])\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-9023.6 -1732.9   127.2  1488.0  9605.7 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -24194.83    3914.71  -6.180 3.95e-09 ***\nhorsepower      34.15      11.63   2.936 0.003748 ** \nlength         102.25      26.36   3.879 0.000146 ***\nengine.size    125.15      11.90  10.515  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3195 on 186 degrees of freedom\nMultiple R-squared:  0.822, Adjusted R-squared:  0.8191 \nF-statistic: 286.3 on 3 and 186 DF,  p-value: &lt; 2.2e-16\n\n\nASSESSMENT OF THE LINEAR MODEL ASSUMPTIONS\nUSING THE GLOBAL TEST ON 4 DEGREES-OF-FREEDOM:\nLevel of Significance =  0.05 \n\nCall:\n gvlma(x = modtr05p1b) \n\n                     Value   p-value                   Decision\nGlobal Stat        20.1508 0.0004663 Assumptions NOT satisfied!\nSkewness            0.3065 0.5798659    Assumptions acceptable.\nKurtosis            5.4282 0.0198143 Assumptions NOT satisfied!\nLink Function      14.1317 0.0001704 Assumptions NOT satisfied!\nHeteroscedasticity  0.2845 0.5937924    Assumptions acceptable.\n\n\n\nCall:\nlm(formula = price ~ horsepower + length + engine.size, data = autos[-c(120, \n    16, 46, 117, 93, 91, 116), ])\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-9200.8 -1729.2   119.1  1394.6  9314.9 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -24062.87    3831.32  -6.281 2.41e-09 ***\nhorsepower      35.29      11.41   3.093 0.002293 ** \nlength         100.18      25.85   3.875 0.000149 ***\nengine.size    126.55      11.59  10.917  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3108 on 182 degrees of freedom\nMultiple R-squared:  0.8336,    Adjusted R-squared:  0.8309 \nF-statistic:   304 on 3 and 182 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\n\n\n\nCall:\nlm(formula = price ~ horsepower + length + engine.size, data = autos[-c(120, \n    16, 46, 117, 93, 91, 116, 113, 112, 64, 91), ])\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-9029.6 -1749.6   110.1  1353.0  9579.6 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -25039.20    3860.18  -6.487 8.31e-10 ***\nhorsepower      37.39      11.42   3.273  0.00128 ** \nlength         108.60      26.15   4.153 5.07e-05 ***\nengine.size    120.65      11.93  10.115  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3099 on 179 degrees of freedom\nMultiple R-squared:  0.828, Adjusted R-squared:  0.8251 \nF-statistic: 287.2 on 3 and 179 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\n\n\n\nCall:\nlm(formula = price ~ horsepower + length + engine.size, data = autos[-c(120, \n    16, 46, 117, 93, 91, 116, 113, 112, 64, 91), ])\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-9029.6 -1749.6   110.1  1353.0  9579.6 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -25039.20    3860.18  -6.487 8.31e-10 ***\nhorsepower      37.39      11.42   3.273  0.00128 ** \nlength         108.60      26.15   4.153 5.07e-05 ***\nengine.size    120.65      11.93  10.115  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3099 on 179 degrees of freedom\nMultiple R-squared:  0.828, Adjusted R-squared:  0.8251 \nF-statistic: 287.2 on 3 and 179 DF,  p-value: &lt; 2.2e-16\n\n\nASSESSMENT OF THE LINEAR MODEL ASSUMPTIONS\nUSING THE GLOBAL TEST ON 4 DEGREES-OF-FREEDOM:\nLevel of Significance =  0.05 \n\nCall:\n gvlma(x = modtr05p1d) \n\n                     Value   p-value                   Decision\nGlobal Stat        23.4321 0.0001038 Assumptions NOT satisfied!\nSkewness            0.9132 0.3392608    Assumptions acceptable.\nKurtosis            6.5750 0.0103421 Assumptions NOT satisfied!\nLink Function      15.7032 0.0000741 Assumptions NOT satisfied!\nHeteroscedasticity  0.2407 0.6237162    Assumptions acceptable.\n\nEste processo poderia continuar, mas não parece ser o mais adequado. Uma inspeção mais detalhada dos dados pode ser uma abordagem melhor. Um modelo que envolva alguma variável categórica, como o fabricante, etc, pode resultar em um modelo mais específico para categorias de carros e assim o modelo pode passar nos testes sobre as hipóteses do método dos mínimos quadrados."
  },
  {
    "objectID": "textos/DiagnosticoHipotesesMetodoMinimosQuadrados.html#usando-o-pacote-easystats-e-outros",
    "href": "textos/DiagnosticoHipotesesMetodoMinimosQuadrados.html#usando-o-pacote-easystats-e-outros",
    "title": "Análise de Modelos de Regressão Linear",
    "section": "Usando o pacote easystats e outros",
    "text": "Usando o pacote easystats e outros\nComo já vimos, um aspecto crucial quando criamos modelos de regressão é avaliar a qualidade do modelo ajustado. Investigamos o quão bem o modelo se ajusta aos dados e quais índices do ajuste devem ser reportado.\nExistem algumas funções para se criar os gráficos diagnósticos – como vimos acima, mas, elas estão espalhadas em vários pacotes do R.\nO pacote performance da coleção do easystats tem como meta preencher esse gap e prover funcionalidades para se computar diversos índices de qualidade do modelo e qualidade do ajuste. Estas medidas incluem o R-quadrado (r^2), o RMSE (root mean squared error) ou o coeficiente de correlação intraclasse (ICC), mas também tem funções para a verificação do modelo com relação a overdispersion, zero-inflation, convergência e singularidade."
  },
  {
    "objectID": "textos/regressaolinear.html",
    "href": "textos/regressaolinear.html",
    "title": "Modelos e Regressão Linear",
    "section": "",
    "text": "Modelagem Estatística é um dos aspectos mais importantes ao se lidar com dados; é um tipo de sumário dos dados.\nUm sumário pode ser uma maneira de se encapsular alguns padrões dos dados. Através da modelagem estatística capturamos tendências e comportamentos presentes nos dados, condensamos toda a informação dos dados para lidarmos mais facilmente ela.\nO modelo estatístico difere do modelo matemático. Enquanto este é derivado apenas de fórmulas, conceitos e manipulações matemáticas, o modelo estatístico é baseado nos dados.\nNesta Trilha abordaremos a Modelagem Estatística, específicamente a Regressão Linear e a Análise de Variância.\nComeçamos com uma apresentação mais cuidadosa do tema Modelagem Estatística, passamos em seguida a Regressão Linear (Modelos Lineares) e finalizamos com Análise de Variância.\nSerão apresentados exemplos de códigos em R, tanto para os cálculos manuais como utilizando as funções disponíveis no software.\nA parte mais difícil de qualquer trabalho estatístico é … começar! E uma das coisas mais difíceis quando se começa é a escolha do tipo correto de análise estatística. A escolha depende:\n\nda natureza dos dados\nda questão que se quer responder, entre outras coisas.\n\nA chave é entender que tipo de variável resposta você tem e saber a natureza de suas variáveis explicativas.\n\nA variável resposta é a coisa com a qual você está trabalhando:\n\né a variável cuja variação você está tentando entender!\né a variável que vai no eixo y do gráfico.\n\nA variável explicativa vai no eixo x do gráfico.\n\nvocê está interessado na extensão em que a variação da variável resposta está associada com a variação da variável explicativa.\n\n\nVocê também precisa considerar o modo que as variáveis na sua análise medem o que elas se propõe a medir. Uma medida contínua é uma variável do tipo altura ou peso que pode assumir valores com números reais.\nUma variável categórica é um fator com dois ou mais níveis:\n\nsexo é um fator com dois níveis (masculino e feminino)\ncor pode ser um fator com sete níveis (vermelho, laranja, amarelo, verde, azul, índigo e violeta)\n\nPortanto, é essencial responder às seguintes questões:\n\nQual das variáveis é a variável resposta?\nQuais são as variáveis explicativas?\nAs variáveis explicativas são contínuas ou categóricas, ou uma mistura de ambas?\nQue tipo de variável resposta temos:\n\né uma medida contínua? uma contagem? uma proporção? um tempo (ocasião) de morte? ou uma categoria?\n\n\n\n\nAlgumas chaves simples para a escolha do método estatístico apropriado\n\n\n\nTodas as variáveis explicativas são contínuas \\(\\Rightarrow\\) Regressão\nTodas as variáveis explicativas são categóricas \\(\\Rightarrow\\) Análise de Variância (ANOVA)\nVariáveis explicativas são tanto contínuas como categóricas \\(\\Rightarrow\\) Análise de Covariância (ANCOVA)\n\n\n\n\n\nContínua \\(\\Rightarrow\\) Regressão Normal, ANOVA ou ANCOVA\nProporção \\(\\Rightarrow\\) Regressão Logística\nContagem \\(\\Rightarrow\\) Modelos log-linear\nBinária \\(\\Rightarrow\\) Análise logística binária\nTempo na morte \\(\\Rightarrow\\) Análise de sobrevivência\n\n\n\n\n\nO objetivo da modelagem é determinar os valores dos parâmetros em um modelo específico que levam ao melhor ajuste do modelo aos dados Os dados são sacrosantos; eles nos dizem o que realmente aconteceu sob determinadas circunstâncias.\n\nÉ um erro comum dizer “os dados foram ajustados ao modelo” como se os dados fossem flexíveis, e nós tivéssemos uma estrutura clara do modelo.\nÉ o contrário: o que se procura é o modelo mínimo adequado que descreva os dados.\nO modelo é ajustado aos dados; não o contrário!\n\nO melhor modelo é o que produz o mínimo de variação não explicada (o mínimo desvio dos resíduos), sujeito à restrição de que todos os parâmetros no modelo devem ser estatisticamente significantes\n\n\n\nUm modelo incorpora nosso entendimento mecanicista das variáveis explicativas envolvidas, e da maneira que elas estão relacionadas com a variável resposta.\nBuscamos um modelo mínimo por conta do princípio da parcimônia, e também um modelo adequado\n\nnão há sentido em ter um modelo inadequado, que não descreve uma fração significante da variação dos dados.\n\nÉ muito importante entender que não há um modelo: \n\nem muitos casos, haverá um grande número de modelos diferentes, uns mais plausíveis do que outros, que podem ser ajustados a qualquer conjunto de dados.\n\nÉ preciso determinar quais, se algum, dos modelos possíveis são adequados:\n\ne depois, dos adequados, qual é o modelo mínimo adequado.\npode haver um conjunto de modelos que descrevem os dados igualmente bem (ou igualmente probremente se a variabilidade é grande)\n\n\n\nUm erro muito comum é tentar fazer a modelagem estatística direto. A melhor coisa a fazer é gastar um tempo substancial, logo de início, para entender os dados e o que eles mostram.\n\nIsto vai ajudar a guiar o pensamento para a modelagem estatística mais apropriada.\n\n\n\n\n\nCertificar-se de que o dataframe está correto em estrutura e conteúdo:\n\nTodos os valores de cada variável estão na mesma coluna?\nTodos os zeros são realmente 0 ou deveriam ser NA?\nCada linha contém o mesmo número de entradas?\nExiste algum nome de variável que contém espaço?\n\nDepois de carregar os dados:\n\nExamine a estrutura com str e certifique-se de as classes e tipos das variáveis estão corretos.\nOlhe no head e no tail dos dados e verifique possíveis erros.\nPlote cada variável individualmente para verificar erros mais grosseiros (plot(x), plot(y), boxplot, etc)\nVeja os relacionamentos entre as variáveis (use tapply, plot, tree e gam)\n\n\n\\(\\Rightarrow\\) Ou seja, explore os dados primeiro!\n\n\n\nPense sobre a escolha do modelo:\n\nQuais variáveis explicativas deveriam ser incluídas?\nQue transformação da resposta é mais apropriada?\nQue interações deveriam ser incluídas?\n\nQuais termos não lineares deveriam ser incluídos?\nHá alguma pseudo-replicação, e se houver, como se deve lidar com isso?\nAs variáveis explicativas deveriam ser transformadas?\n\n\nTente utilizar o tipo mais simples de análise que seja apropriado para seus dados e para a questão que está tentando responder:\n\nFaça uma ANOVA one-way ao invés de um modelo de efeitos mistos\n\nAjuste um modelo máximo e vá simplificando-o paulatinamente ao remover parâmetros\nVerifique o modelo mínimo adequado em termos de constância de variância e normalidade dos erros utilizando plot(model)\nEnfatize os tamanhos dos efeitos e erros padrões (summary.lm) e analise a tabela de desvios (summary.aov)\nPor fim, documente tudo o que fizer, e explique cada um dos passos. Desta maneira você entenderá o que fez e porque fez quando retornar à sua análise 6 meses mais tarde!\n\n\n\nO que, exatamente, queremos dizer quando afirmamos que os valores dos parâmetros devem dar conta do melhor ajuste do modelo aos dados ?\nA convenção utilizada é que nossas técnicas devem levar a estimadores que minimizem a variância e sejam livres de viés.\nNós definimos melhor em termos da “máxima verosimilhança”.\nUma definição funcional para estes termos é:\n\nDados os dados,\ne dada nossa escolha do modelo,\nquais valores dos parâmetros deste modelo\nfarão os dados observados mais prováveis?\n\nJulgamos o modelo com base em quão prováveis os dados seriam se o modelo estivesse correto!\n\n\n\n\nUma das coisas mais importantes que fazemos na modelagem estatística diz respeito à simplificação de modelos.\nO princípio da parcimônia é atribuído a um filósofo nominalista britânico do século 14, William de Occam.\nEle insistia que, dado um conjunto de explicações igualmente boas para um determinado fenômeno, a explicação correta é a explicação mais simples.\nEste princípio é chamado de “navalha de Occam” porque ele cortava suas explicações às formas mais simples: seu argumento era que, ao explicar algo, hipóteses não precisavam ser desnecessariamente multiplicadas.\nPara a modelagem estatística, o princípio da parcimônia significa que:\n\nmodelos devem ter tão poucos parâmetros quanto possível;\nmodelos lineares devem ser preferidos a modelos não-lineares;\nexperimentos que dependem de poucas hipóteses devem ser preferidos em relação àqueles que dependem de muitas;\nmodelos devem ser gradualmente reduzidos até que sejam mínimos e adequados;\nexplicações simples devem ser preferidas às complexas."
  },
  {
    "objectID": "textos/regressaolinear.html#método-estatístico-apropriado",
    "href": "textos/regressaolinear.html#método-estatístico-apropriado",
    "title": "Modelos e Regressão Linear",
    "section": "",
    "text": "Algumas chaves simples para a escolha do método estatístico apropriado\n\n\n\nTodas as variáveis explicativas são contínuas \\(\\Rightarrow\\) Regressão\nTodas as variáveis explicativas são categóricas \\(\\Rightarrow\\) Análise de Variância (ANOVA)\nVariáveis explicativas são tanto contínuas como categóricas \\(\\Rightarrow\\) Análise de Covariância (ANCOVA)\n\n\n\n\n\nContínua \\(\\Rightarrow\\) Regressão Normal, ANOVA ou ANCOVA\nProporção \\(\\Rightarrow\\) Regressão Logística\nContagem \\(\\Rightarrow\\) Modelos log-linear\nBinária \\(\\Rightarrow\\) Análise logística binária\nTempo na morte \\(\\Rightarrow\\) Análise de sobrevivência"
  },
  {
    "objectID": "textos/regressaolinear.html#objetivo-da-modelagem-estatística",
    "href": "textos/regressaolinear.html#objetivo-da-modelagem-estatística",
    "title": "Modelos e Regressão Linear",
    "section": "",
    "text": "O objetivo da modelagem é determinar os valores dos parâmetros em um modelo específico que levam ao melhor ajuste do modelo aos dados Os dados são sacrosantos; eles nos dizem o que realmente aconteceu sob determinadas circunstâncias.\n\nÉ um erro comum dizer “os dados foram ajustados ao modelo” como se os dados fossem flexíveis, e nós tivéssemos uma estrutura clara do modelo.\nÉ o contrário: o que se procura é o modelo mínimo adequado que descreva os dados.\nO modelo é ajustado aos dados; não o contrário!\n\nO melhor modelo é o que produz o mínimo de variação não explicada (o mínimo desvio dos resíduos), sujeito à restrição de que todos os parâmetros no modelo devem ser estatisticamente significantes"
  },
  {
    "objectID": "textos/regressaolinear.html#especificando-o-modelo",
    "href": "textos/regressaolinear.html#especificando-o-modelo",
    "title": "Modelos e Regressão Linear",
    "section": "",
    "text": "Um modelo incorpora nosso entendimento mecanicista das variáveis explicativas envolvidas, e da maneira que elas estão relacionadas com a variável resposta.\nBuscamos um modelo mínimo por conta do princípio da parcimônia, e também um modelo adequado\n\nnão há sentido em ter um modelo inadequado, que não descreve uma fração significante da variação dos dados.\n\nÉ muito importante entender que não há um modelo: \n\nem muitos casos, haverá um grande número de modelos diferentes, uns mais plausíveis do que outros, que podem ser ajustados a qualquer conjunto de dados.\n\nÉ preciso determinar quais, se algum, dos modelos possíveis são adequados:\n\ne depois, dos adequados, qual é o modelo mínimo adequado.\npode haver um conjunto de modelos que descrevem os dados igualmente bem (ou igualmente probremente se a variabilidade é grande)\n\n\n\nUm erro muito comum é tentar fazer a modelagem estatística direto. A melhor coisa a fazer é gastar um tempo substancial, logo de início, para entender os dados e o que eles mostram.\n\nIsto vai ajudar a guiar o pensamento para a modelagem estatística mais apropriada.\n\n\n\n\n\nCertificar-se de que o dataframe está correto em estrutura e conteúdo:\n\nTodos os valores de cada variável estão na mesma coluna?\nTodos os zeros são realmente 0 ou deveriam ser NA?\nCada linha contém o mesmo número de entradas?\nExiste algum nome de variável que contém espaço?\n\nDepois de carregar os dados:\n\nExamine a estrutura com str e certifique-se de as classes e tipos das variáveis estão corretos.\nOlhe no head e no tail dos dados e verifique possíveis erros.\nPlote cada variável individualmente para verificar erros mais grosseiros (plot(x), plot(y), boxplot, etc)\nVeja os relacionamentos entre as variáveis (use tapply, plot, tree e gam)\n\n\n\\(\\Rightarrow\\) Ou seja, explore os dados primeiro!\n\n\n\nPense sobre a escolha do modelo:\n\nQuais variáveis explicativas deveriam ser incluídas?\nQue transformação da resposta é mais apropriada?\nQue interações deveriam ser incluídas?\n\nQuais termos não lineares deveriam ser incluídos?\nHá alguma pseudo-replicação, e se houver, como se deve lidar com isso?\nAs variáveis explicativas deveriam ser transformadas?\n\n\nTente utilizar o tipo mais simples de análise que seja apropriado para seus dados e para a questão que está tentando responder:\n\nFaça uma ANOVA one-way ao invés de um modelo de efeitos mistos\n\nAjuste um modelo máximo e vá simplificando-o paulatinamente ao remover parâmetros\nVerifique o modelo mínimo adequado em termos de constância de variância e normalidade dos erros utilizando plot(model)\nEnfatize os tamanhos dos efeitos e erros padrões (summary.lm) e analise a tabela de desvios (summary.aov)\nPor fim, documente tudo o que fizer, e explique cada um dos passos. Desta maneira você entenderá o que fez e porque fez quando retornar à sua análise 6 meses mais tarde!\n\n\n\nO que, exatamente, queremos dizer quando afirmamos que os valores dos parâmetros devem dar conta do melhor ajuste do modelo aos dados ?\nA convenção utilizada é que nossas técnicas devem levar a estimadores que minimizem a variância e sejam livres de viés.\nNós definimos melhor em termos da “máxima verosimilhança”.\nUma definição funcional para estes termos é:\n\nDados os dados,\ne dada nossa escolha do modelo,\nquais valores dos parâmetros deste modelo\nfarão os dados observados mais prováveis?\n\nJulgamos o modelo com base em quão prováveis os dados seriam se o modelo estivesse correto!"
  },
  {
    "objectID": "textos/regressaolinear.html#o-princípio-da-parcimônia-navalha-de-occam",
    "href": "textos/regressaolinear.html#o-princípio-da-parcimônia-navalha-de-occam",
    "title": "Modelos e Regressão Linear",
    "section": "",
    "text": "Uma das coisas mais importantes que fazemos na modelagem estatística diz respeito à simplificação de modelos.\nO princípio da parcimônia é atribuído a um filósofo nominalista britânico do século 14, William de Occam.\nEle insistia que, dado um conjunto de explicações igualmente boas para um determinado fenômeno, a explicação correta é a explicação mais simples.\nEste princípio é chamado de “navalha de Occam” porque ele cortava suas explicações às formas mais simples: seu argumento era que, ao explicar algo, hipóteses não precisavam ser desnecessariamente multiplicadas.\nPara a modelagem estatística, o princípio da parcimônia significa que:\n\nmodelos devem ter tão poucos parâmetros quanto possível;\nmodelos lineares devem ser preferidos a modelos não-lineares;\nexperimentos que dependem de poucas hipóteses devem ser preferidos em relação àqueles que dependem de muitas;\nmodelos devem ser gradualmente reduzidos até que sejam mínimos e adequados;\nexplicações simples devem ser preferidas às complexas."
  },
  {
    "objectID": "textos/regressaolinear.html#análise-de-regressão",
    "href": "textos/regressaolinear.html#análise-de-regressão",
    "title": "Modelos e Regressão Linear",
    "section": "Análise de Regressão",
    "text": "Análise de Regressão\nA Análise de Regressão é utilizada para se explicar ou modelar o relacionamento entre uma única variável \\(Y\\), chamada de variável resposta, de saída ou dependente e uma ou mais variáveis preditoras, de entrada ou explicativas, \\(X_1, X_2, ..., X_p\\).\nQuando \\(p = 1\\), é chamada regressão simples\nQuando \\(p &gt; 1\\) é chamada regressão múltipla ou algumas vezes, regressão multivariada.\nA variável resposta deve ser uma variável contínua\nAs variáveis explicativas podem ser contínuas, discretas ou categóricas.\n\nA Análise de Regressão tem vários possíveis objetivos, incluindo:\n\nPredição de observações futuras\nAvaliação do efeito de, ou do relacionamento entre, as variáveis explicativas sobre a resposta\nUma descrição geral da estrutura dos dados\n\n\n\nHistória\nProblemas do tipo regressão foram abordados primeiramente no século 18, e estavam relacionados ao uso da astronomia na navegação (Faraway (2014)).\nLegendre desenvolveu o método dos mínimos quadrados em 1805.\nGauss disse que o tinha desenvolvido alguns anos antes e mostrou, em 1809, que os mínimos quadrados eram a solução ótima quando os erros tem uma distribuição normal.\nA metodologia ficou restrita às ciências físicas até a parte final do século 19, quando em 1875, Francis Galton cunhou o termo regressão à mediocridade (Galton (1886))."
  },
  {
    "objectID": "textos/regressaolinear.html#modelo-linear",
    "href": "textos/regressaolinear.html#modelo-linear",
    "title": "Modelos e Regressão Linear",
    "section": "Modelo Linear",
    "text": "Modelo Linear\nUm modelo linear entre duas variáveis \\(X\\) e \\(Y\\), é definido matematicamente como uma equação com dois parâmetros desconhecidos (Peck, Olsen, e Devore (2012)),\n\\[ y = b_0 + b_1x \\] que é uma estimativa da linha de regressão verdadeira da população:\n\\[\\mu_y = \\beta_0 + \\beta_1 x\\]\nEsta linha de regressão descreve como a resposta média \\(\\mu_y\\) muda com \\(x\\).\nOs valores observados para \\(y\\) variam em torno da sua média \\(\\mu_y\\) e assumimos que tem o mesmo desvio padrão \\(\\sigma\\).\nOs valores ajustados \\(b_0\\) e \\(b_1\\) estimam o verdadeiro deslocamento (intercept) e a inclinação da linha de regressão da população.\nPara fins de simplificação, indicamos \\(Y \\equiv \\mu_y\\) na fórmula:\n\\[ Y = \\beta_0 + \\beta_1 X \\]\nAssim, dados \\(n\\) pares de valores, \\((X_1, Y_1), (X_2, Y_2), \\ldots, (X_n, Y_n)\\), se for admitido que \\(Y\\) é função linear de \\(X\\), pode-se estabelecer uma regressão linear simples, cujo modelo estatístico é\n\\[ Y_i = \\beta_0 + \\beta_1 X_i + e_i, \\quad i = 1, 2, \\ldots, n \\]"
  },
  {
    "objectID": "textos/regressaolinear.html#ajustando-um-modelo-linear",
    "href": "textos/regressaolinear.html#ajustando-um-modelo-linear",
    "title": "Modelos e Regressão Linear",
    "section": "Ajustando um modelo linear",
    "text": "Ajustando um modelo linear\nComo através de uma amostra obtemos uma estimativa da verdadeira equação de regressão, denominamos\n\\[\\hat{Y}_i = \\hat{\\beta}_0 + \\hat{\\beta}_1 X_i \\]\nou seja, \\(\\hat{Y}_i\\) é o valor estimado de \\(Y_i\\), através das estimativas de \\(\\beta_0\\) e \\(\\beta_1\\), que chamaremos de \\(\\hat{\\beta}_0\\) e \\(\\hat{\\beta}_1\\). Para cada valor de \\(Y_i\\), temos um valor \\(\\hat{Y}_i\\) estimado pela equação de regressão,\n\\[Y_i = \\hat{Y}_i + e_i \\]\nOu seja, podemos expressar o modelo como: DADOS = AJUSTE + RESÍDUO, onde o termo AJUSTE representa a expressão \\(\\beta_0 + \\beta_1 X\\).\nPortanto, o resíduo (ou desvio) de cada observação em relação ao modelo adotado será\n\\[\\begin{array}{lll}\n    e_i & = & Y_i - \\hat{Y}_i \\\\\n    e_i & = & Y_i - (\\hat{\\beta_0 }+ \\hat{\\beta_1} X_i)\n\\end{array} \\]"
  },
  {
    "objectID": "textos/regressaolinear.html#ajustando-um-modelo-linear-primeira-abordagem",
    "href": "textos/regressaolinear.html#ajustando-um-modelo-linear-primeira-abordagem",
    "title": "Modelos e Regressão Linear",
    "section": "Ajustando um modelo linear – primeira abordagem",
    "text": "Ajustando um modelo linear – primeira abordagem\nComo parte das hipóteses da Regressão Linear, consideramos que os resíduos possuem uma distribuição normal com média zero e variância constante, ou seja, \\(e_i \\sim \\text{N}(0, \\sigma^2)\\).\nA solução de mínimos quadrados vai determinar \\(\\hat{\\beta_0}\\) e \\(\\hat{\\beta_1}\\) que minimizam a soma dos quadrados dos resíduos (residuals sum of squares – RSS):\n\\[\\begin{array}{lll} \\\\\n  RSS & = & \\sum_{i=1}^n(Y_i - \\hat{Y_i})^2 \\\\\n      & = & \\sum_{i=1}^n[y_i - (\\beta_0 + \\beta_1 x_i)]^2 \\\\\n      & = & \\sum e_i^2 \\\\\n      & = & E \\equiv E_2(\\beta_0,\\beta_1)\n  \\end{array} \\]\nComo se trata de uma função de duas variáveis, no processo de encontrar os pontos de mínimos, utilizamos derivadas de primeira ordem e as igualamos a zero:\n\\[\\frac{\\partial E}{\\partial \\beta_0} = 0 \\;\\; \\mbox { e }\\;\\; \\frac{\\partial E}{\\beta_1} = 0\\] Expandindo as equações acima teremos: \\[0 = \\frac{\\partial }{\\partial \\beta_0}\\sum_{i=1}^n[y_i - (\\beta_0 + \\beta_1 x_i)]^2 = 2 \\sum_{i=1}^n(y_i - \\beta_1x_i - \\beta_0)(-1)\\] e \\[0 = \\frac{\\partial }{\\partial \\beta_0}\\sum_{i=1}^n[y_i - (\\beta_0 + \\beta_1 x_i)]^2 = 2 \\sum_{i=1}^n(y_i - \\beta_1x_i - \\beta_0)(-x_i)\\] Simplificando estas duas equações, chegamos a um sistema com duas equações e duas incógnitas, que resulta nas seguintes expressões para estimar os parâmetros \\(\\beta_0\\) e \\(\\beta_1\\):\n\\[\\begin{array}{lll}\n    \\hat{\\beta}_1 & = & \\frac{\\sum_{i=1}^{n} X_iY_i - \\frac{\\sum_{i=1}^{n}\n        X_i \\sum_{i=1}^{n} Y_i}{n}}{\\sum_{i=1}^{n}X_i^2 -\n      \\frac{(\\sum_{i=1}^{n} X_i)^2}{n}} \\\\\n      &  & \\\\\n    \\hat{\\beta}_1  & = & \\frac{n\\sum_{i=1}^{n} X_iY_i - \\sum_{i=1}^{n}\n        X_i \\sum_{i=1}^{n} Y_i}{n\\sum_{i=1}^{n}X_i^2 -\n      (\\sum_{i=1}^{n} X_i)^2} \\\\\n      &  & \\\\\n  \\hat{\\beta}_0 & = & \\frac{\\sum_{i=1}^nX_i^2\\sum_{i=1}^nY_i - \\sum_{i=1}^nX_iY_i\\sum_{i=1}^nX_i}{n\\sum_{i=1}^{n}X_i^2 -\n      (\\sum_{i=1}^{n} X_i)^2}  \\\\\n      &  & \\\\\n    \\hat{\\beta}_0 & = & \\bar{Y} - \\hat{\\beta}_1 \\bar{X}\n\\end{array}\n\\]\nonde\n\\[\n\\begin{aligned}\n    \\bar{Y} & =  \\frac{1}{n} \\sum_{i=1}^{n} Y_i \\qquad \\text{e} \\qquad \\\\\n    \\bar{X} & =  \\frac{1}{n} \\sum_{i=1}^{n} X_i\n\\end{aligned}\n\\]\nO processo envolve a determinação dos seguintes valores (juntamente com o RSS acima), conhecidos como os “famosos cinco no R”:\n\n\\(\\sum Y_i^2\\)\n\\(\\sum Y_i\\)\n\\(\\sum X_i^2\\)\n\\(\\sum X_i\\)\n\\(\\sum X_iY_i\\)\n\n\nSomas corrigidas dos quadrados e soma dos produtos\nDepois dos famosos cinco, vamos calcular três somas essenciais “corrigidas”.\n\\[SSX = \\sum x^2 - \\frac{(\\sum x)^2}{n}\\]\n\\[SSY = \\sum y^2 - \\frac{(\\sum y)^2}{n}\\]\nO terceiro termo é a soma corrigida dos produtos, \\(SSXY\\).\n\\[SSXY = \\sum xy - \\frac{(\\sum x)(\\sum y)}{n} \\]"
  },
  {
    "objectID": "textos/regressaolinear.html#somas-corrigidas-evitando-erros-de-arredondamento",
    "href": "textos/regressaolinear.html#somas-corrigidas-evitando-erros-de-arredondamento",
    "title": "Modelos e Regressão Linear",
    "section": "Somas corrigidas – evitando erros de arredondamento",
    "text": "Somas corrigidas – evitando erros de arredondamento\nAs expressões para os cálculos das somas corrigidas e soma dos produtos envolvem cálculos computacionais potencialmente perigosos em termos de precisão.\nSubtrações de valores grandes podem gerar erros de arredondamento consideráveis.\nPara evitar isso, podemos utilizar as seguintes fórmulas equivalentes:\n\\[SSY = \\sum(y - \\bar{y})^2\\] \\[SSX = \\sum(x - \\bar{x})^2\\] \\[SSXY = \\sum(y - \\bar{y})(x - \\bar{x})\\]\n\nCalculando os parâmetros\nOs parâmetros do modelo (\\(y = b_0 + b_1x\\)) podem ser determinados com os valores anteriores:\n\\[b_1 = \\frac{SSXY}{SSX}\\]\nUma parte da definição do melhor ajuste da linha reta é que ela passa através do ponto (\\(\\bar{x},\\bar{y}\\)), determinado pelos valores médios de \\(x\\) e \\(y\\).\nComo sabemos que \\(y = b_0 + b_1x\\), então também temos que \\(\\bar{y} = b_0 + b_1\\bar{x}\\).\nAssim:\n\\[b_0 = \\bar{y} - b_1\\bar{x} = \\frac{\\sum y}{n} - b_1\\frac{\\sum x}{n}\\]\n\n\nIncertezas nas estimativas dos parâmetros\n\nErro padrão na inclinação\nA incerteza na inclinação estimada aumenta com o aumento da variância e diminui com o aumento do número de pontos no gráfico.\nAlém disso, a incerteza é maior quando a faixa de valores de \\(x\\) (conforme medida por SSX) é pequena:\n\\[se_{b_1} = \\sqrt{\\frac{MSE}{SSX}}\\]\n\n\nErro padrão do deslocamento\nA incerteza do deslocamento estimado tem o mesmo comportamento da incerteza na inclinação com relação à variância, ao número de pontos e à faixa de valores de \\(x\\).\nAlém disso, ela também aumenta com o quadrado da distância entre a origem e o valor médio de \\(x\\) (conforme medido por \\(\\sum x^2\\)):\n\\[se_{b_0} = \\sqrt{\\frac{MSE\\sum x^2}{n \\times SSX}}\\]"
  },
  {
    "objectID": "textos/regressaolinear.html#verificando-o-ajuste-do-modelo-linear-r2",
    "href": "textos/regressaolinear.html#verificando-o-ajuste-do-modelo-linear-r2",
    "title": "Modelos e Regressão Linear",
    "section": "Verificando o ajuste do Modelo Linear – \\(R^2\\)",
    "text": "Verificando o ajuste do Modelo Linear – \\(R^2\\)\nDepois de ajustado um modelo linear, podemos nos perguntar “O quão bem ele ajusta os dados?\nUma medida deste ajuste é o \\(R^2\\):\n\nCoeficiente de determinação ou percentual da variância explicada\n\n\\[R^2 = 1 - \\frac{\\sum(\\hat{y}_i - y_i)^2}{\\sum(y_i - \\bar{y})^2} = 1 - \\frac{\\mbox{RSS}}{\\mbox{SSY}} \\]\nonde:\n\nRSS: residual sum of squares (soma dos quadrados dos resíduos)\nSSY: sum of squares of response variable (soma dos quadrados de \\(y\\))\n\nA faixa de \\(R^2\\) é: \\(0 \\leq R^2 \\leq 1\\) + Valores próximos a 1 indicam melhor ajuste. + Para regressão linear simples, \\(R^2 = r^2\\), onde \\(r\\) é a correlação entre \\(x\\) e \\(y\\). + Esta definição de \\(R^2\\) só faz sentido se o modelo tem um deslocamento.\nO \\(R\\)-quadrado obtido desta forma é chamado de \\(R^2\\) múltiplo – que é a fração da variância total explicada pelo modelo.\nHá um outro \\(R\\)-quadrado que é o R-quadrado ajustado, cujo valor é muito próximo, mas tem uma definição um pouco diferente.\nAo invés de ser baseado na soma dos quadrados dos resíduos (RSS) explicados e na soma total dos quadrados do modelo SSY, ele é baseado na variância global, dada por: \\[s^2_T = \\frac{SSY}{(n-1)}\\]\ne na variância do erro, \\(s^2\\) – chamada de “Erro quadrado médio” (MSE), dado por: \\[\\sum(y_i - \\hat{y_i})^2/(n-2) = RSS/DFE\\]\nonde DFE é o número de graus de liberdade no cálculo do erro (\\(n-2\\))\nAssim, o \\(R^2\\) ajustado será dado por:\n\\[R^2_{ajustado} = \\frac{s^2_T - s^2}{s^2_T}\\] \\[R^2_{ajustado} = \\frac{\\frac{SSY}{(n-1)} - MSE}{\\frac{SSY}{(n-1)}}\\]\nOutra maneira de se calcular o R quadrado ajustado é pela expressão: \\[R^2_{ajustado} = 1 - \\left[\\frac{(1 - R^2)(n - 1)}{n - k - 1} \\right]\\] onde:\n\n\\(n\\) é o número de pontos nos dados da amostra;\n\\(k\\) é o número de regressores independentes, i.e., o número de variáveis no modelo, excluindo a constantae.\n\n\nSignificado do \\(R^2\\) ajustado\nComo vimos, tanto o \\(R^2\\) como o \\(R^2_{ajustado}\\) nos dão uma ideia de quantos pontos de dados caem dentro da equação de regressão. Contudo, há uma diferença principal entre o \\(R^2\\) e o \\(R^2_{ajustado}\\): o \\(R^2\\) assume que cada variável explicativa explica a variação na variável dependente. O \\(R^2_{ajustado}\\) nos diz o percentual de variação explicada somente pelas variáveis independentes que realmente afetam a variável dependente.\n\n\nProblemas com o \\(R^2\\) que são corrigidos pelo \\(R^2_{ajustado}\\)\n\nO \\(R^2\\) aumenta com cada preditora adicionada a um modelo. Como o \\(R^2\\) sempre aumenta e nunca diminui, pode parecer que se tem um modelo melhor conforme se aumenta o número de termos adicionados ao modelo. Isto pode ser completamente equivocado.\nDe modo similar, se o modelo tem muitos termos e muitos polinômios de alta ordem, pode-se cair no problema de over-fitting dos dados. Quando se tem o over-fitting de dados, um valor muito alto de \\(R^2\\) pode levar a projeções equivocadas."
  },
  {
    "objectID": "textos/regressaolinear.html#análise-de-variância-para-regressão-linear",
    "href": "textos/regressaolinear.html#análise-de-variância-para-regressão-linear",
    "title": "Modelos e Regressão Linear",
    "section": "Análise de Variância para Regressão Linear",
    "text": "Análise de Variância para Regressão Linear\nPara avaliar a significância do modelo, realizamos uma Análise de Variância (ANOVA) para a regressão. Esta análise visa avaliar se o modelo obtido (\\(\\beta_0 \\mbox{ e } \\beta_1\\)) é estatisticamente diferente do modelo nulo, ou seja, o modelo onde o coeficiente \\(\\beta_1\\), que dá a inclinação da reta, seja nulo.\nComo vimos na estimação dos parâmetros, o objetivo é encontrar parâmetros que façam com que a soma de quadrados dos resíduos seja mínima.\nO conceito básico da regressão é DADOS = AJUSTE + RESÍDUOS, que podemos escrever como: \\[ (y_i - \\bar{y}) = (\\hat{y_i} - \\bar{y}) + (y_i - \\hat{y_i})\\] O primeiro termo é a variação total na variável resposta \\(y\\), o segundo termo é a variação na resposta média e o terceiro termo é o valor residual.\nSe um modelo é bem ajustado, esperamos que a soma de quadrados do modelo seja grande e que a soma de quadrados dos resíduos seja mínima.\n\nElevando ao quadrado e adicionando os termos para as \\(n\\) observações temos:\n\\[\\sum(y_i - \\bar{y})^2 = \\sum(\\hat{y_i} - \\bar{y})^2 + \\sum(y_i - \\hat{y_i})^2\\]\nPodemos particionar a soma de quadrados da seguinte forma:\n\\[SST = SSM + RSS \\]\nSS é soma dos quadrados e T, M e R são: total, modelo e resíduos, respectivamente.\nA variância da amostra \\(s_y^2\\) é \\(\\sum(y_i - \\bar{y})^2/(n-1) = SST/DFT\\), ou seja, a soma total dos quadrados dividida pelo total de graus de liberdade (DFT).\nPara regressão linear simples, a MSM (média quadrada do modelo) é \\(\\sum(\\hat{y_i} - \\bar{y})^2/(1) = SSM/DFM\\), já que um modelo de regressão linear simples tem apenas uma variável explicativa \\(x\\).\nO Erro quadrado médio (MSE) é dado por \\(\\sum(y_i - \\hat{y_i})^2/(n-2) = RSS/DFE\\), que é a estimativa da variância sobre a linha de regressão da população (\\(\\sigma^2\\)).\nNormalmente, os cálculos da ANOVA são mostrados em uma tabela de análise de variância que tem o formato apresentado no Quadro Tabela 1 para regressão linear simples:\n\n\nTabela 1: Formato do Resultado da Análise de Variância\n\n\n\n\n\n\n\n\n\nFonte\nGraus de Liberdade\nSoma dos Quadrados\nQuadrado Médio\nF\n\n\n\n\nModelo\n\\(1\\)\n\\(\\sum(\\hat{y_i}-\\bar{y})^2\\)\nSSM/DFM\nMSM/MSE\n\n\nResíduo\n\\(n-2\\)\n\\(\\sum(y_i - \\hat{y_i})^2\\)\nRSS/DFE\n\n\n\n\n\n\n\n\n\n\nTotal\n\\(n-1\\)\n\\(\\sum(y_i - \\bar{y})^2\\)\nSST/DFT\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA coluna “F” provê uma estatística para testar a hipótese de que \\(\\beta_1 \\neq 0\\) contra a hipótese nula de que \\(\\beta_1 = 0\\). Em outras palavras, estamos testando o modelo nulo (que só considera o intercept) contra o modelo alternativo com a variável explicativa. São modelos aninhados: o modelo nulo está contido no modelo alternativo.\nA estatística de teste é a razão MSM/MSE. Quando o termo MSM é grande relativamente ao termo MSE, então a razão é grande e há evidência contra a hipótese nula. Para regressão linear simples, a estatística MSM/MSE tem uma distribuição \\(F\\) com os graus de liberdade dados por (DFM, DFE) = \\((1, n-2)\\).\n\nO teste estatístico é comparar o valor da distribuição \\(F\\) para estes graus de liberdade com o valor obtido acima.\n\nNo R isso é feito com a função qf que dá os quantis da distribuição \\(F\\)\n\n\nO teste F pode ser expresso genericamente como (Peck, Olsen, e Devore (2012)): \\[F = \\frac{\\left(\\frac{RSS_1 - RSS_2}{p_2 - p_1}\\right)}{\\left(\\frac{RSS_2}{n-p_2}\\right)}\\] onde \\(RSS_i\\) é a soma dos quadrados dos resíduos do modelo \\(i\\).\n\nConsiderando dois modelos, 1 e 2, onde o modelo 1 é aninhado dentro do modelo 2, o modelo 1 tem \\(p_1\\) parâmetros e o modelo 2 tem \\(p_2\\) parâmetros, sendo \\(p_1 &lt; p_2\\). A hipótese é que o modelo 2, que tem mais parâmetros, explique melhor a variância dos dados. E esta explicação deve ser significativamente relevante. Então o teste F vai fazer esta avaliação; no R, a função qf vai ser utilizada para obtermos o valor da estatística F da seguinte forma:\nqf(prob, df1, df2, ...)   onde:\n\n\\(prob\\) é o nível de confiança (probabilidade para a qual queremos o quantil);\n\\(df1 = p_2 - p_1\\)\n\\(df2 = n - p_2\\)\n\nO modelo nulo tem um parâmetro apenas – o intercept; logo \\(p_1 = 1\\); o modelo alternativo tem dois parâmetros (o intercept e a variável explicativa); logo \\(p_2 = 2\\).\nOutra possibilidade é verificar a probabilidade de se obter um valor de \\(F\\) tão grande como o dado pela razão MSM/MSE com estes graus de liberdade. Neste caso utilizamos a função de distribuição de probabilidade acumulada ao invés dos quantis.\n\nComo queremos a área de rejeição da hipótese, usamos 1 - pf\n\nNo próximo capítulo veremos exemplos de Análise de Regressão e teremos a oportunidade de utilizar estes conceitos no exercício tutoriado."
  },
  {
    "objectID": "textos/regressaolinear.html#análise-de-regressão-exemplo-2",
    "href": "textos/regressaolinear.html#análise-de-regressão-exemplo-2",
    "title": "Modelos e Regressão Linear",
    "section": "Análise de Regressão – Exemplo 2",
    "text": "Análise de Regressão – Exemplo 2\n\nPodemos ilustrar o efeito da regressão utilizando dados de exames de alunos que fizeram um determinado curso de estatística.\n\nOs dados estão no Moodle: stat500.csv\n\nApós lermos os dados, fazemos um procedimento chamado padronização, que é deixar os dados com média “zero” e desvio padrão “um”.\n\nPara isso, utilizamos a função scale do R.\n\n\n\n\nCódigo\nstat500uns &lt;- read.csv(\"../datasets/stat500.csv\", header = TRUE)\nstat500 &lt;- data.frame(scale(stat500uns))\nstr(stat500)\n'data.frame':   55 obs. of  4 variables:\n $ midterm: num  0.872 0.455 0.664 0.664 0.455 ...\n $ final  : num  -0.09909 -0.40188 0.00184 1.61671 0.80927 ...\n $ hw     : num  0.564 0.489 0.514 0.739 0.264 ...\n $ total  : num  0.585 0.211 0.516 1.392 0.713 ...\nsapply(stat500, mean)\n      midterm         final            hw         total \n 3.571549e-16 -2.157444e-16  3.073368e-16  5.344994e-16 \nsapply(stat500, sd)\nmidterm   final      hw   total \n      1       1       1       1 \n\n\n\nVamos plotar as notas no exame final versus as notas do exame midterm\n\nTambém colocamos uma linha do tipo \\(y = x\\)\n\n\n\n\nCódigo\nplot(final ~ midterm, stat500)\nabline(0, 1)\n\n\n\n\n\n\nVamos calcular o ajuste da regressão por mínimos quadrados e plotar a linha de regressão. Também vamos calcular as correlações.\n\n\n\n\n\nCódigo\ng &lt;- lm(final ~ midterm, stat500)\ncor(stat500)\n          midterm      final         hw     total\nmidterm 1.0000000 0.54522775 0.27205756 0.8444568\nfinal   0.5452277 1.00000000 0.08733764 0.7788629\nhw      0.2720576 0.08733764 1.00000000 0.5644286\ntotal   0.8444568 0.77886293 0.56442864 1.0000000\n\n\n\n\n\nCódigo\nplot(final ~ midterm, stat500)\nabline(0, 1)\nabline(g$coef, lty = 5)\n\n\n\n\n\n\n\n\nVemos que para os alunos que tiraram 1 SD acima da média no midterm, prevemos que terão uma nota um pouco abaixo que isto na média no exame final (veja a linha tracejada da regressão)\n\n\\(0.54523\\) SD acima da média para ser exato.\n\nDo mesmo modo, um estudante que tirou menos do que a média no midterm, é esperado que vá relativamente melhor no exame final, apesar que ainda abaixo da média.\nEsta é a regressão à mediocridade que Galton estudou e descreveu, com relação à altura de pais e filhos.\n\nPais altos tendem a ter filhos altos, mas não tão altos quanto seus pais.\nPais baixos tendem a ter filhos baixos, mas não tão baixos quanto seus pais.\n\nVerificando o ajuste\n\n\n\nCódigo\nsummary(g)\n\nCall:\nlm(formula = final ~ midterm, data = stat500)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.0049 -0.5363  0.1064  0.6024  1.8745 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -3.999e-16  1.141e-01   0.000        1    \nmidterm      5.452e-01  1.151e-01   4.735 1.67e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.8462 on 53 degrees of freedom\nMultiple R-squared:  0.2973,    Adjusted R-squared:  0.284 \nF-statistic: 22.42 on 1 and 53 DF,  p-value: 1.675e-05\n\n\n\nVerificando o ajuste – ANOVA\n\n\n\nCódigo\nanova(g)\nAnalysis of Variance Table\n\nResponse: final\n          Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nmidterm    1 16.053  16.053  22.421 1.675e-05 ***\nResiduals 53 37.947   0.716                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "textos/regressaolinear.html#diagnósticos-da-regressão",
    "href": "textos/regressaolinear.html#diagnósticos-da-regressão",
    "title": "Modelos e Regressão Linear",
    "section": "Diagnósticos da Regressão",
    "text": "Diagnósticos da Regressão\n\nTemos utilizado até aqui a função summary() para termos os parâmetros do modelo e um sumário das estatísticas.\nInfelizmente, nada na saída da função summary(model) nos diz se o nosso modelo é apropriado.\n\nOu seja, que satisfizemos as hipóteses estatísticas subjacentes ao nosso modelo.\nNossa confiança nas inferências sobre os parâmetros da regressão dependem do grau em que conseguimos atender as hipóteses estatísticas do modelo de minimos quadrados ordinários – OLS.\n\nPor que isso é importante?\n\nIrregularidades nos dados ou uma especificação errada dos relacionamentos entre as variáveis preditoras e a variável resposta pode nos levar a especificar um modelo amplamente impreciso.\nTambém podemos concluir que uma variável preditora e a variável resposta não estão relacionadas, quando na verdade, estão.\n\nOu o contrário!\n\n\nO R tem muitos métodos para se avaliar as hipóteses estatísticas em uma análise de regressão.\nA abordagem mais comum é aplicar a função plot() ao objeto retornado pela função lm().\nFazendo isso, teremos quatro gráficos que são úteis para se avaliar o ajuste de modelo."
  },
  {
    "objectID": "textos/regressaolinear.html#gráficos-diagnósticos-da-regressão",
    "href": "textos/regressaolinear.html#gráficos-diagnósticos-da-regressão",
    "title": "Modelos e Regressão Linear",
    "section": "Gráficos Diagnósticos da Regressão",
    "text": "Gráficos Diagnósticos da Regressão\n\nTopo-esquerda\nMostra os resíduos no eixo y contra os valores ajustados no eixo x. Não se deve observar estruturas ou padrões no gráfico. Os pontos devem se parecer como o céu à noite. É um problema se os pontos se espalham conforme os valores ajustados ficam maiores – como se fosse uma fatia de queijo. A amplitude de variação dos resíduos deve ser independente dos valores ajustados.\n\n\nTopo-direita\nGráfico qqnorm (normal) que deve ser uma linha reta se os erros são normalmente distribuídos. Se o gráfico tivesse a forma de um S ou de uma banana precisariamos ajustar um modelo diferente."
  },
  {
    "objectID": "textos/regressaolinear.html#usando-o-pacote-lmtest-para-avaliar-o-modelo",
    "href": "textos/regressaolinear.html#usando-o-pacote-lmtest-para-avaliar-o-modelo",
    "title": "Modelos e Regressão Linear",
    "section": "Usando o pacote lmtest para avaliar o modelo",
    "text": "Usando o pacote lmtest para avaliar o modelo\nVamos utilizar a função bptest que executa o teste de Breusch-Pagan, que ajusta um modelo linear de regressão aos resíduos de um modelo de regressão linear (por default as mesmas variáveis explicativas são utilizadas como no modelo principal de regressão) e rejeita se muito da variância é explicada pelas variáveis explanatórias adicionais.\nA hipótese nula do teste é que o modelo tem variância constante, ou seja, é um teste de homocedasticidade do nosso modelo.\n\n\nCódigo\nlibrary(lmtest)\n\n\n\n\nCódigo\nbptest(g)\n\n    studentized Breusch-Pagan test\n\ndata:  g\nBP = 0.86813, df = 1, p-value = 0.3515\n\n\nComo o p-value do teste é maior do que 0.05, aceitamos a hipótese nula de que a variância é constante."
  },
  {
    "objectID": "textos/regressaolinear.html#exercício-1",
    "href": "textos/regressaolinear.html#exercício-1",
    "title": "Modelos e Regressão Linear",
    "section": "Exercício 1",
    "text": "Exercício 1\nVamos utilizar o conjunto de dados que mostra o crescimento de lagartas (“caterpillars”)” alimentadas com uma dieta experimental que difere no conteúdo de tannin.\n\nNosso objetivo é construir um modelo para explicar o crescimento das lagartas a partir da dieta.\nAs etapas apresentadas neste Exemplo são as etapas típicas de uma análise de regressão.\n\nLeitura dos Dados\n\n\n\n\n\n\n  \n    \n    \n      growth\n      tannin\n    \n  \n  \n    12\n0\n    10\n1\n    8\n2\n    11\n3\n    6\n4\n    7\n5\n    2\n6\n    3\n7\n    3\n8\n  \n  \n  \n\n\n\n\n\n\nExaminando os dados – gráfico de dispersão\nA figura abaixo apresenta um gráfico de dispersão das variáveis tannin e growth.\n\n\n\n\n\nOlhando o gráfico podemos fazer uma estimativa grosseira dos parâmetros no olho.\n\nQuais as suas estimativas?\n\nO conteúdo de tannin (eixo \\(x\\)) aumentou por 8 unidades, em resposta ao que o crescimento growth (\\(y\\)) declinou de cerca de 12 unidades para 2 unidades.\nUma mudança de \\(-10\\) unidades no crescimento!\nA inclinação \\(b_1\\) é a mudança em \\(y\\) dividida pela mudança em \\(x\\), assim: \\[ b_1 \\approx \\frac{-10}{8} = -1.25\\] Agora, conclua o exercício:\n\nDetermine o modelo de regressão linear simples entre as variáveis tannin e growth.\nCalcule e interprete os coeficientes de correlação (\\(r\\)) e determinação (\\(r^2\\))."
  },
  {
    "objectID": "textos/regressaolinear.html#exercício-2",
    "href": "textos/regressaolinear.html#exercício-2",
    "title": "Modelos e Regressão Linear",
    "section": "Exercício 2",
    "text": "Exercício 2\nUm artigo publicado na revista Technometrics, de SC Narula, e JF Wellington (Prediction, linear regression, and a minimum sum of relative errors), apresenta dados de preços de vendas e taxas anuais para 24 casas.\n\nDados\nOs dados do artigo mencionado estão disponíveis no arquivo: montgomery_11-4.txt\nCom isso:\n\nFaça a importação dos dados, verifique sua estrutura e faça um sumário estatístico.\n\nImportação\nEstrutura\nSumário\n\n\n\n\n\n\n\n\n  \n    \n    \n      Venda\n      Taxas\n    \n  \n  \n    25.9\n4.9176\n    29.5\n5.0208\n    27.9\n4.5429\n    25.9\n4.5573\n    29.9\n5.0597\n    29.9\n3.8910\n    30.9\n5.8980\n    28.9\n5.6039\n    35.9\n5.8282\n    31.5\n5.3003\n    31.0\n6.2712\n    30.9\n5.9592\n    30.0\n5.0500\n    36.9\n8.2464\n    41.9\n6.6969\n    40.5\n7.7841\n    43.9\n9.0384\n    37.5\n5.9894\n    37.9\n7.5422\n    44.5\n8.7951\n    37.9\n6.0831\n    38.9\n8.3607\n    36.9\n8.1400\n    45.8\n9.1416\n  \n  \n  \n\n\n\n\n\nFaça um gráfico apropriado para relacionar o preço de vendas às taxas pagas (o preço de venda varia conforme as taxas, ou seja, o preço é a variável dependente).\nCalcule o modelo de regressão linear, determinando os coeficientes e \\(r^2\\) padrão e o ajustado."
  },
  {
    "objectID": "textos/regressaolinear.html#exercício-3",
    "href": "textos/regressaolinear.html#exercício-3",
    "title": "Modelos e Regressão Linear",
    "section": "Exercício 3",
    "text": "Exercício 3\nPara uma amostra de oito operadores de máquina, foram coletados o número de horas de treinamento (\\(x\\)) e o tempo necessário para completar o trabalho (\\(y\\)). Os dados coletados encontram-se na tabela abaixo:\n\n\n\nx\n5,2\n5,1\n4,9\n4,6\n4,7\n4,8\n4,6\n4,9\n\n\n\n\ny\n13\n15\n18\n20\n19\n17\n21\n16\n\n\n\nPede-se:\n\nFaça o gráfico de dispersão para esses dados.\nDetermine o modelo de regressão linear simples entre as variáveis \\(x\\) e \\(y\\).\nCalcule e interprete os coeficientes de correlação (\\(r\\)) e determinação (\\(r^2\\)).\n\n\nReferências\n\n\nFaraway, Julian James. 2014. Linear Models with R. 2nd ed. Boca Raton, FL: Chapman; Hall/CRC Press. https://www.routledge.com/Linear-Models-with-R/Faraway/p/book/9781439887332.\n\n\nGalton, Francis. 1886. «Regression Towards Mediocrity in Hereditary Stature.» The Journal of the Anthropological Institute of Great Britain and Ireland 15: 246–63. http://www.jstor.org/stable/2841583.\n\n\nPeck, Roxy, Chris Olsen, e Jay L. Devore. 2012. Introduction to Statistics and Data Analysis. 4th ed. Boston, MA – USA: Brooks/Cole, CENGAGE Learning."
  }
]