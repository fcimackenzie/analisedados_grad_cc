---
title: "Introdução à Inferência Estatística"
author: Mário Olímpio de Menezes
section-titles: false
format: 
  beamer:
    theme: CambridgeUS
    fonttheme: structurebold
    highlight: tango
    toc: false
    slide_level: 2
knitr: 
   opts_chunk: 
     collapse: true
     strip.white: true
     tidy: true
     comment: ""
     continue: false
     warning: false
     message: false

---


```{r}
#| label: setup
#| cache: false
#| include: false
#source("setup_knitr_slides.R")
#op <- par(no.readonly = TRUE)
#library(xtable)
## O pacote printr já configura o formato de saída de muitas funções
## como head(), table(), etc, sem a necessidade de usar a função
## knitr::kable(). Veja: https://yihui.name/printr
#loadNamespace("printr")
## Para desabilitar, use
## unloadNamespace("printr")
```


# Introdução

## Inferência estatística

Na **inferência estatística** os dois principais objetivos são:

- **Estimar** um parâmetro populacional
  - Estimativa pontual
  - Estimativa intervalar
- **Testar** uma hipótese ou afirmativa sobre um parâmetro populacional

## Estimação

Se $\theta$ é um parâmetro da distribuição de uma v.a. X e $X_1, ..., X_n$ é uma *amostra* desta distribuição, temos as duas abordagens de estimativa:

### 1. Estimação pontual

* Apresentar **um valor** para $\theta$ que é uma função da amostra $X_1, ..., X_n$ (cálculo de $\theta$), chamada de *estimador* de $\theta$

* Espera-se que o estimador tenha boas propriedades:
    i. **em média** esteja próximo de $\theta$
    ii. o estimador **se aproxima de $\theta$** quando **n** aumenta, ...

## Estimação 

#### 2. Estimação intervalar

* Apresentar **um intervalo de possíveis valores** para $\theta$, chamado de *intervalo de confiança*. Os limites do intervalo são funções da amostra $X_1, ..., X_n$ (são aleatórios).

\centering
\resizebox{!}{2cm}{
\includegraphics{figuras/intervalo-confianca-theta.png}
}
\raggedright

* A probabilidade de que o intervalo contenha $\theta$ deve ser **alta**

* A *amplitude* do intervalo de ser tão **pequena** quanto possível (intervalo mais *preciso*)

## Testes de hipótese

### Hipótese
É uma afirmativa sobre uma propriedade da população

### Teste de hipótese
- É um procedimento para se testar uma afirmativa sobre uma
propriedade da população
- Permite tomar **decisões** sobre a população com base em
informações de dados amostrais.

## Exemplo 1

Suponha que, no ar não poluído, a concentração de certa substância
se comporta segundo um modelo Normal com média 14 unidades/ml e
desvio padrão 6 unidades/ml.

Quando um determinado poluente está presente em excesso, esta substância
tem concentração média alterada para 18 unidades/ml.

Admitimos que o modelo Normal com desvio padrão 6 unidades/ml, continua
representado de forma adequada a concentração da substância no ar poluído.

## Exemplo 1

```{r}
#| label: sadio-doente
#| fig.width: 7.0
#| fig.height: 5.0
#| out.width: 80%
dnorm1 <- function(x) {dnorm(x, mean = 14, sd = 6)}
dnorm2 <- function(x) {dnorm(x, mean = 18, sd = 6)}
curve(dnorm1, from = -10, to = 40, col = "green",
      ylab = "", xlab = "Concentração no Ar", axes = FALSE)
axis(1, at = c(14, 18))
box()
abline(v = 14, lty = 2, col = "green")
curve(dnorm2, from = -10, to = 40, add = TRUE, col = "red")
abline(v = 18, lty = 2, col = "red")
legend("topright", legend = c("Normal", "Poluído"),
       lty = 1, col = c("green", "red"))
```

## Exemplo 1

Para averiguar se um tratamento é eficaz contra este tipo de poluição, selecionamos
uma amostra de 30 volumes de ar **submetidos ao tratamento**.

Assumimos que todos os elementos da amostra $X_1, \ldots, X_{30}$ possuem
a mesma distribuição: $X_i \sim \text{N}(\mu, 36)$, onde:

  - $\mu = 14$ se o tratamento for eficiente
  - $\mu = 18$ se o tratamento não for eficiente

Se a média da amostra for próxima de 14, temos **evidências** de que o
tratamento é eficaz. Se for mais próxima de 18, as **evidências** são
contrárias ao tratamento.

Então a pergunta é: o quão próximo é **"próximo"**?

## Exemplo 2

Deseja-se estudar a tolerância de um equipamento eletrônico ao número de
impactos termo-elétricos.

Pelas características de fabricação do equipamento, é possível admitir
que a probabilidade de falha seja constante, isto é, após cada impacto,
existe uma probabilidade $p$ que ele falhe.

Representando por $X$ a variável número de impactos anteriores à falha,
pretende-se verificar se o modelo Geométrico com $p = 0.4$ é adequado
para caracterizar essa variável.

# Teste para a Média Populacional

## Variância conhecida

### Exemplo 1 - continuação

- Interesse geral $\mu = 14$?
- Distribuição da média amostral para $n = 30$: $\text{N}(\mu, 36/30)$.
- Critério para decidir sobre o valor de $\mu$.
- **Valor crítico**, digamos $x_c$ tal que se a média amostral
($\bar{x}_{obs}$) for maior que $x_c$ concluímos que a amostra pertence
ao ar com média $18$.
- Como $\bar{X}$ é uma variável aleatória, devem existir erros
  associados.

## Tipos de hipóteses

### Hipótese nula $H_0$

É uma afirmativa de que o valor de um parâmetro populacional é
**igual** a algum valor especificado. (O termo *nula* é
usado para indicar nenhuma mudança, nenhum efeito).

- No ex. 1 temos: $\mu = 18$ unidades/ml (tratamento não teve efeito)
- No ex. 2 temos: $p = 0,4$

### Hipótese alternativa $H_1$ ou $H_a$

É uma afirmativa de que o parâmetro tem um valor, que, de alguma
forma, difere da hipótese nula. Ex.:

- $p \neq 0,4$ \qquad $p < 0,4$ \qquad $p > 0,4$

## Tipos de hipóteses

Quando fazemos um teste de hipótese, chegamos a um dos dois
possíveis resultados:

- **Rejeitar $H_0$**: em favor da hipótese alternativa $H_1$
- **Não rejeitar $H_0$**: e conclui-se que não existem diferenças

### Atenção!

- Mesmo quando **aceitamos** a hipótese nula, não significa dizer que temos 100\% de certeza da decisão.
- Sempre existe uma probabilidade de **erro** associado a todo teste de hipótese

## Hipóteses

**Hipótese simples**:

- $H_0:$ O tratamento não é eficaz ($\mu = 18$)
- $H_1:$ O tratamento é eficaz ($\mu = 14$)

**Hipóteses compostas**:

- Hipótese unilateral à esquerda
  - $H_0:$ O tratamento não é eficaz ($\mu = 18$);
  - $H_1:$ O tratamento é eficaz ($\mu < 18$).
- Hipótese bilateral:
  - $H_0:$ O tratamento não é eficaz ($\mu = 18$);
  - $H_1:$ O tratamento é eficaz ($\mu \neq 18$).

## Erros ao realizar um teste de hipótese

```{r}
#| out.width: 70%
#| fig-align: center
knitr::include_graphics("./figuras/errors.jpg")
```

## Erros ao realizar um teste de hipótese

- **Erro Tipo I**: rejeitar $H_0$, quando $H_0$ é verdadeira.
- **Erro Tipo II**: não rejeitar $H_0$ quando $H_0$ é falsa.

\begin{table}[h]
\centering
\begin{tabular}{c|cc}
\hline
& \textbf{$H_o$ verdadeira} & \textbf{$H_o$ falsa} \\
\hline
\textbf{Não rejeitar $H_0$} & Decisão correta & Erro tipo II \\
\textbf{Rejeitar $H_0$} & Erro tipo I & Decisão correta \\
\hline
\end{tabular}
\end{table}

## Erros ao realizar um teste de hipótese

Definimos por $\alpha$  e $\beta$ as probabilidades de cometer os erros
do tipo I e II:

- $\alpha = P(\text{erro tipo I}) = P(\text{rejeitar } H_0 \, | \, H_0
  \text{ verdadeira})$
- $\beta = P(\text{error tipo II}) = P(\text{não rejeitar } H_0 \, | \, H_0
  \text{ falsa})$

No exemplo 1, se $H_0: \mu = 18$ e $H_a: \mu < 18$, então:

- $\alpha = P(\text{concluir que o tratamento é eficaz quando na verdade não é})$
- $\beta = P(\text{concluir que o tratamento não é eficaz quando na verdade é})$



## Erros ao realizar um teste de hipótese

```{r}
#| label: erro1
#| fig.width: 7.0
#| fig.height: 5.0
#| out.width: 80%
## Usando a distribuição amostral
dnorm2 <- function(x) {dnorm(x, mean = 18, sd = 6/sqrt(30))}
curve(dnorm2, from = 8, to = 25, col = "red",
      ylab = "", xlab = "Concentração no Ar", axes = FALSE)
box()
abline(v = 18, lty = 2, col = "red")
xc <- qnorm(0.05, mean = 18, sd = 6/sqrt(30))
axis(1, at = c(xc, 18), labels = c(expression(x[c]), 18))
cord.x <- c(8, seq(8, xc, 0.01), xc)
cord.y <- c(0, dnorm(seq(8, xc, 0.01), mean = 18, sd = 6/sqrt(30)), 0)
polygon(x = cord.x, y = cord.y, col = "gray", border = NA)
legend("topright", legend = c(expression(alpha)),
       fill = c("gray"))
```

## Erros ao realizar um teste de hipótese

```{r}
#| label: erro2
#| fig.width: 7.0
#| fig.height: 5.0
#| out.width: 80%
## Usando a distribuição amostral
dnorm2 <- function(x) {dnorm(x, mean = 18, sd = 6/sqrt(30))}
curve(dnorm2, from = 8, to = 25, col = "red",
      ylab = "", xlab = "Concentração no Ar", axes = FALSE)
box()
abline(v = 18, lty = 2, col = "red")
xc <- qnorm(0.05, mean = 18, sd = 6/sqrt(30))
axis(1, at = c(xc, 18), labels = c(expression(x[c]), 18))
cord.x <- c(8, seq(8, xc, 0.01), xc)
cord.y <- c(0, dnorm(seq(8, xc, 0.01), mean = 18, sd = 6/sqrt(30)), 0)
polygon(x = cord.x, y = cord.y, col = "gray", border = NA)
dnorm1 <- function(x) {dnorm(x, mean = 14, sd = 6/sqrt(30))}
curve(dnorm1, from = 8, to = 25, add = TRUE, col = "green")
abline(v = 14, lty = 2, col = "green")
axis(1, at = 14)
cord.x2 <- c(xc, seq(xc, 25, 0.01), 30)
cord.y2 <- c(0, dnorm(seq(xc, 25, 0.01), mean = 14, sd = 6/sqrt(30)), 0)
polygon(x = cord.x2, y = cord.y2, col = "black",
        density = 15, angle = 45, border = NA)
legend("topright", legend = c(expression(alpha), expression(beta)),
       fill = c("gray", "black"), angle = c(NA, 45), density = c(NA, 20))
```

## Erros ao realizar um teste de hipótese

A situação ideal é aquela em que ambas as probabilidades, $\alpha$ e
$\beta$, são próximas de zero.

No entanto, à medida que diminuimos $\alpha$, a probabilidade $\beta$
tende a aumentar.

Levando isso em conta, ao formular as hipóteses, **devemos cuidar para que
o erro mais importante a ser evitado seja o erro do tipo I**.

Por isso, a probabilidade $\alpha$ recebe o nome de **nível de
significância** do teste, e é esse erro que devemos controlar.

## Valor crítico

Supondo $\alpha$ conhecido podemos determinar o valor crítico $x_c$.
\begin{align*}
\alpha &= P(\text{erro tipo I}) = P(\text{rejeitar } H_0 \, | \, H_0
\text{ verdadeira}) \\
 &= P(\bar{X} < x_c \, | \, \mu = 18) = P\left( \frac{\bar{X} -
 \mu}{\sigma/\sqrt{n}} < \frac{x_c - 18}{6/\sqrt{30}} \right) \\
 &= P(Z < z_c)
\end{align*}

com $Z \sim N(0,1)$.

## Obtendo o valor crítico

Dado $\alpha$ encontramos $z_c$ na tabela normal padrão.

Obtemos $x_c$
$$
z_c = \frac{x_c - 18}{6/\sqrt{30}} \quad \Rightarrow \quad x_c = 18 +
z_c \frac{6}{\sqrt{30}}
$$

Supondo $\alpha = 0.05$ temos
$$
0.05 = P(Z < z_c) \quad \Rightarrow \quad z_c = -1.64
$$
logo
$$
x_c = 18 - 1.64 \frac{6}{\sqrt{30}} = 16.2
$$

## Região Crítica

Dada uma amostra, se $\bar{x}_{obs} < 16.2$, **rejeitamos** $H_0$,
concluindo que o tratamento é eficaz.

O conjunto dos números reais menores que 16.2 é denominado de **Região
de Rejeição** ou **Região Crítica** (RC), isto é:
$$
RC = \{ x \in \mathbb{R} : x < 16.2 \}.
$$
**No exemplo 1**, se a média amostral dos 30 volumes foi
$\bar{x}_{obs} = 16.04$, então **rejeitamos** $H_0$, ao nível de
significância $\alpha = 0.05$.

Nesse caso, $\bar{x}_{obs} < x_c$ está dentro da RC.

## Região Crítica

```{r}
#| label: rc
#| fig.width: 7.0
#| fig.height: 5.0
#| out.width: 80%
## Usando a distribuição amostral
dnorm2 <- function(x) {dnorm(x, mean = 18, sd = 6/sqrt(30))}
curve(dnorm2, from = 8, to = 25, col = "red",
      ylab = "", xlab = "", axes = FALSE)
box()
abline(v = 18, lty = 2, col = "red")
xc <- qnorm(0.05, mean = 18, sd = 6/sqrt(30))
axis(1, at = c(xc, 18), labels = c(round(xc,1), 18))
cord.x <- c(8, seq(8, xc, 0.01), xc)
cord.y <- c(0, dnorm(seq(8, xc, 0.01), mean = 18, sd = 6/sqrt(30)), 0)
polygon(x = cord.x, y = cord.y, col = "gray", border = NA)
dnorm1 <- function(x) {dnorm(x, mean = 14, sd = 6/sqrt(30))}
curve(dnorm1, from = 8, to = 25, add = TRUE, col = "green")
abline(v = 14, lty = 2, col = "green")
axis(1, at = 14)
cord.x2 <- c(xc, seq(xc, 25, 0.01), 30)
cord.y2 <- c(0, dnorm(seq(xc, 25, 0.01), mean = 14, sd = 6/sqrt(30)), 0)
legend("topright", legend = "RC", fill = "gray")
xobs <- 16.04
text(x = xobs, y = -0.1, xpd = TRUE,
     labels = bquote(bar(x)[obs] == .(xobs)), col = "blue")
arrows(x0 = xobs, y0 = 0, x1 = xobs, y1 = -0.09, xpd = TRUE,
       length = 0.1, col = "blue")
```

## Teste de hipótese bilateral

Definindo as hipóteses
$$
H_0: \mu = \mu_0 \quad \text{e} \quad H_a: \mu \neq \mu_0
$$
A Região Crítica será dada por
$$
RC = \{x \in \mathbb{R} \, | \, x < x_{c_1} \quad \text{ou} \quad x >
x_{c_2} \}
$$
Para um valor de $\alpha$ fixado, determinamos $x_{c_1}$ e $x_{c_2}$ de modo
que
$$
P(\bar{X} < x_{c_1} \cup \bar{X} > x_{c_2}) = \alpha
$$
Assim, distribuimos a área $\alpha$ igualmente entre as duas partes da RC
$$
P(\bar{X} < x_{c_1}) = \frac{\alpha}{2} \quad \text{e} \quad P(
\bar{X} > x_{c_2}) = \frac{\alpha}{2}
$$

## Teste de hipótese bilateral

```{r}
#| label: rc2
#| fig.width: 7.0
#| fig.height: 5.0
#| out.width: 80%
## Usando a distribuição amostral
dnorm2 <- function(x) {dnorm(x, mean = 0, sd = 2)}
curve(dnorm2, from = -10, to = 10,
      ylab = "", xlab = "", axes = FALSE)
box()
abline(v = 0, lty = 2)
xc1 <- qnorm(0.05/2, mean = 0, sd = 2)
xc2 <- qnorm(0.05/2, mean = 0, sd = 2, lower.tail = FALSE)
axis(1, at = c(xc1, 0, xc2),
     labels = c(expression(x[c1]), expression(mu[0]), expression(x[c2])))
cord.x1 <- c(-10, seq(-10, xc1, 0.01), xc1)
cord.y1 <- c(0, dnorm(seq(-10, xc1, 0.01), sd = 2), 0)
polygon(x = cord.x1, y = cord.y1, col = "gray", border = NA)
cord.x2 <- c(xc2, seq(xc2, 10, 0.01), 10)
cord.y2 <- c(0, dnorm(seq(xc2, 10, 0.01), sd = 2), 0)
polygon(x = cord.x2, y = cord.y2, col = "gray", border = NA)
legend("topright", legend = "RC", fill = "gray")
text(x = xc2, y = 0.001, labels = expression(alpha/2), pos = 4)
text(x = xc1, y = 0.001, labels = expression(alpha/2), pos = 2)
```

## Etapas de um teste de hipótese

1. Estabelecer as hipóteses nula e alternativa.
2. Definir a forma da região crítica, com base na hipótese alternativa.
3. Identificar a distribuição do estimador e obter sua estimativa.
4. Fixar $\alpha$ e obter a região crítica.
   i. Em algumas situações pode ser o inverso: Fixamos a região crítica (limites) e calculamos o $\alpha$
5. Concluir o teste com base na estimativa e na região crítica.

## Exemplo

Uma indústria adquire de um certo fabricante pinos cuja resistência média à ruptura é especificada em 60 unid. (**valor nominal** da especificação). Em um determinado dia, a indústria recebeu um grande lote de pinos e a equipe técnica da indústria deseja verificar se o lote atende às especificações.

* **$H_0$**: O lote atende às especificações (Hipótese **nula**)
* **$H_1$**: O lote não atende às especificações (Hipótese **alternativa**)

A v.a. $X$ (resistência à ruptura) é tal que $X \sim N(\mu,25)$. O problema pode ser resolvido testando as hipóteses.

* $H_0: \mu = 60$ (hipótese simples: um único valor)
* e $H_1: \mu \neq 60$ (hipótese composta: mais de um valor)

## Teste de Hipóteses

\small

* Uma **hipótese estatística** é uma afirmação sobre o(s) parâmetro(s) da distribuição de probabilidade de uma característica (v.a. $X$) da população.
* Um **teste** de uma hipótese estatística é um procedimento ou **regra de decisão** que nos possibilida decidir por $H_0$ ou $H_1$ com base na amostra $X_1, ..., X_n$.

**Exemplo** --- A equipe técnica da indústria decidiu retirar uma amostra aleatória de tamanho $n = 16$ do lote recebido. A resistência de cada pino foi medida e foi calculada a resistência média $\bar{X}$ (*estimador* de $\mu$), que será utilizada para realizar o teste (**estatística de teste**). Podemos afirmar que $$\bar{X} \sim N\left(\mu,\frac{25}{16}\right)$$

\small

* **Obs.:** Se $X_1, X_2, ..., X_n$ é uma amostra de uma distribuição $N(\mu,\sigma^2)$, então a **média amostral** tem distribuição $N(\mu, \sigma^2/n)$
* para quais valores de $\bar{X}$ a equipe técnica deve rejeitar $H_0$ e portanto rejeitar o lote?

## Teste de Hipóteses

\small 

* **Região Crítica** ($R_c$) ou região **de rejeição** é o conjunto de valores assumidos pela estatística de teste para os quais a hipótese nula é **rejeitada**. Seu complementar é a **região de aceitação** ($R_a$).
* **Exemplo** --- Se o lote está fora de especificação, isto é, se $H_1: \mu \neq 60$ for verdadeira, espera-se que a média amostral seja inferior ou superior a 60 unid.

* A equipe técnica decidiu adotar a seguinte regra:
    + **rejeitar** $H_0$ se $\bar{X}$ for maior do que 62,5 unid. ou menor do que 57,5 unid.
    + neste caso, a *região crítica* foi estabelecida (através de limites); depois calculamos o $\alpha$ correspondente.
* As duas regiões são:
$$R_c = \{\bar{X} > 62,5 \mbox{ ou } \bar{X} < 57,5\}: \mbox{ região de \textbf{rejeição} de } H_0 \mbox{ e}$$
$$R_a = \{57,5 \leq \bar{X} \leq 62,5 \}: \mbox{ região de \textbf{aceitação} de } H_0$$

## Teste de Hipóteses

\centering
\resizebox{9cm}{!}{
\includegraphics{figuras/ilustracao-teste-hipotese.png}
}

### Procedimento (teste):

* Se $\bar{x} \in R_c$, rejeita-se $H_0$;
* Se $\bar{x} \ni R_c$, não se rejeita (aceita-se) $H_0$.

## Tipos de erros

* Erro tipo I: **rejeitar** $H_0$ quando $H_0$ é **verdadeira**
* Erro tipo II: **não rejeitar** (**aceitar**) $H_0$ quando $H_0$ é **falsa**.

**Exemplo** --- As hipóteses são:

* $H_0$: O lote atende às especificações;
* $H_1$; O lote não atende às especificações.

Erro tipo I: **rejeitar** o lote sendo que ele está **de acordo** com as especificações

Erro tipo II: **não rejeitar** (**aceitar**) o lote sendo que ele **não está de acordo** com as especificações.


## Nível de Significância e Poder

### {-}

* $P(\mbox{Erro tipo I}) = \alpha$ (**nível de significância**)
    * $\alpha = P(\mbox{Rejeitar }H_0; H_0 \mbox{ verdadeira})$

### {-}

* $P(\mbox{Erro tipo II}) = \beta = P(\mbox{Não rejeitar }H_0; H_0 \mbox{ falsa})$
    * $= P(\mbox{ Não rejeitar } H_0; H_1 \mbox{ verdadeira})$
    * $1 - \beta = P(\mbox{ Rejeitar }H_0; H_0 \mbox{ é falsa})$ : **poder do teste**.

**Obs.:** Quanto maior o poder, melhor o teste.

## Nível de Significância e Poder


As hipóteses são $H_0: \mu=60$ e $H_1: \mu \neq 60$. Logo
$$ \alpha = P(\bar{X} > 62,5 \mbox{ ou } \bar{X} < 57,5; H_0: \mu =60)$$
Se $H_0$ for verdadeira, então $\bar{X} \sim N(60,25/16)$

Calculamos o nível de significância:
\small

$$\alpha = P(\bar{X} > 62,5;H_0: \mu=60) + P(\bar{X} < 57,5; H_0: \mu=60)$$
$$=P\left(\frac{\bar{X} - 60}{\sqrt{25/16}} > \frac{62,5 - 60}{\sqrt{25/16}}\right) + P\left(\frac{\bar{X} - 60}{\sqrt{25/16}} < \frac{57,5 - 60}{\sqrt{25/16}}\right)$$
$$=P(Z > 2,00) + P(Z < -2,00) = 0,02275 + 0,02275 = 0,0455$$

\scriptsize
```{r}
#| echo: true
#| include: true
alpha = 1 - pnorm(2) + 1 - pnorm(2)
alpha
```

## Nível de Significância e Poder

Cálculo de $\alpha$:

\centering
\resizebox{9cm}{!}{
\includegraphics{figuras/calculo-alpha.png}
}

## Nível de Significância e Poder

Cálculo de $\beta$
\small

$\beta = P(\mbox{Não rejeitar } H_0; H_1 \mbox{ verdadeira}) = P(57,5 \leq \bar{X} \leq 62,5; H_1: \mu \neq 60)$

Como exemplo de cálculo de $\beta$, selecionamos $H_1: \mu = 63,5$. Logo:
$$\bar{X} \sim N\left(63,5;\frac{25}{16}\right) \mbox{ e } \beta=P(57,5 \leq \bar{X} \leq 62,5; H_1: \mu = 63,5)$$

\centering
\resizebox{!}{4cm}{
\includegraphics{figuras/calculo-beta.png}
}

## Nível de Significância e Poder

\footnotesize
Cálculo de $\beta$; efetuando o cálculo no R:


\scriptsize
```{r}
#| tidy: true
#| echo: true
#| include: true
n = 16
sigma = sqrt(25)
sem = sigma/sqrt(n)
# alpha calculado anteriormente
mu0 = 60
I = c(alpha/2, 1-alpha/2)
q = qnorm(I, mean=mu0, sd=sem); q
mu = 63.5
p = pnorm(q, mean=mu, sd=sem); p
diff(p)
poder = 1 - diff(p); poder
```


\scriptsize
Se a média verdadeira for 63.5, a probabilidade que nós rejeitemos a 
hipótese nula é de aproximadamente `r round(poder*100,2)`\%



## Hipóteses bilateral e unilaterais

\small
Se as hipóteses nula e alterantiva são:

* $H_0: \mu = \mu_0$;
* $H_1: \mu \neq \mu_0$;

em que $\mu_0$ é uma constante conhecida (**valor de teste**), o teste é chamado de **bilateral**

Podemos ter também as hipóteses:

* $H_0: \mu = \mu_0$;
* $H_1: \mu < \mu_0$. $\leftarrow$  *unilateral à esquerda*

ou 

* $H_0: \mu = \mu_0$; 
* $H_1: \mu > \mu_0$. $\leftarrow$ *unilateral à direita*.

É interessante expressar $H_0$ em forma de igualdade, ou seja, fazer teste bilateral.




## Hipóteses bilateral e unilateral

### Exemplo
Um fabricante de um certo componente afirma que o *tempo médio* de vida dos componentes produzidos é de **1000 horas**. Engenheiros de produto têm interesse em verificar se uma modificação do processo de fabricação *aumenta* a duração dos componentes.

Hipóteses:

* $H_0: \mu = 1000 \mbox{ horas}$
* $H_1: \mu > 1000 \mbox{ horas}$

sendo $\mu$ o tempo médio de duração dos componentes

## Procedimento básico de testes de hipóteses

O procedimento de teste de hipóteses relativo ao parâmetro $\theta$ de uma população é decomposto em quatro passos:

#### (i) Formulação das **hipóteses**

* $H_0: \theta = \theta_0$;
* $H_1: \theta < \theta_0 \mbox{ ou } \theta > \theta_0 \mbox{ ou } \theta \neq \theta_0$.

#### (ii) Identificação da **estatística de teste**
e caracterização da sua **distribuição** (por exemplo, método de substituição)

## Procedimento básico de testes de hipóteses

#### (iii) Escolha do nível de significância do teste
$\alpha = 0.05, 0.01, 0.005$ são valores comuns 

e obtenção da **região crítica**

#### (iv) Cálculo da Estatístia de teste
e tomada de decisão ($H_0$ deve ser rejeitada ou não?)

## Teste de hipóteses para uma média populacional

Considere uma amostra aleatória de tamanho $n$ de uma população normal com média $\mu$ (desconhecida) e variância $\sigma^2$ (conhecida).

Iniciamos pelo teste unilateral à esquerda:

\small

#### (i)
* $H_0: \mu = \mu_0$;
* $H_1: \mu < \mu_0$.

#### (ii)
A estatística de teste é a média amostral $\bar{X}$ (estimador pontual de $\mu$). Se a distribuição da população é normal ou se a amostra é grande ($n \geq 30$), mesmo que a distribuição da população não seja normal) a distribuição de $\bar{X} \sim N(\mu, \sigma^2/n)$. Se $H_0$ for verdadeira, então:
$$Z = \frac{\sqrt{n}(\bar{X} - \mu_0)}{\sigma} \sim N(0,1)$$

## Teste de hipóteses para uma média populacional

\small

#### (iii)
Rejeitamos $H_0$ em favor de $H_1$ se a média amostral $\bar{X}$ é "pequena" em relação a $\mu_0$. A região crítica é obtida selecionando-se um $k$ tal que $R_c = \{\bar{X} < k \}$, sendo que $P(\bar{X} < k; H_0: \mu=\mu_0) = \alpha$, 


:::: {.columns}

::: {.column width="70%"}

\footnotesize

Ou seja, sob $H_0$
$$P\left(\frac{\bar{X} - \mu_0}{\sigma/\sqrt{n}} - \frac{k -\mu_0}{\sigma/\sqrt{n}}\right) = P\left(Z < \frac{k - \mu_0}{\sigma/\sqrt{n}}\right) = \alpha$$
$$\Rightarrow \frac{k - \mu_0}{\sigma/\sqrt{n}} = z_{\alpha} \Rightarrow k = \mu_0 + z_{\alpha} \times \frac{\sigma}{\sqrt{n}}$$
$$\Rightarrow R_c = \{\bar{X} < \mu_0 + z_{\alpha} \times \frac{\sigma}{\sqrt{n}}\}$$

\textbf{Obs.:} $z_{\alpha} < 0$.

:::

::: {.column width="30%"}
\centering
\resizebox{!}{3cm}{
\includegraphics{figuras/teste-hipot-zalpha.png}
}

:::

::::


## Teste de hipóteses para uma média populacional

#### (iv) Conclusão:
se $\bar{x} \in R_c = \{\bar{X} < \mu_0 + z_{\alpha} \times \frac{\sigma}{\sqrt{n}}\}$, rejeita-se $H_0$; caso contrário, não se rejeita $H_0$.



## Teste de hipóteses para uma média populacional

### Exemplo

Um comprador de tijolos suspeita de uma diminuição na resistência. De experiências anteriores, sabe-se que a resistência média ao desmoronamento de tais tijolos é igual a 200 kg, com um desvio padrão de 10 kg. Uma amostra de 100 tijolos, escolhidos ao acaso, forneceu uma média de 195 kg. A um nível de significância de 5\%, pode-se afirmar que a resistência média ao desmoronamento
diminuiu?

#### (i) As hipóteses de interesse são:
* $H_0: \mu=200\mbox{ kg}$
* $H_1: \mu < 200 \mbox{ kg}$

## Exemplo -- cont.

\small 

### (ii) Estatística de teste
A estatística de teste é a média amostral $\bar{X}$. Como $n = 100 \geq 30$, tem-se que sob $H_0, \bar{X} \sim N\left(200,\frac{100}{100}\right)$, aproximadamente.

### (iii) Região Crítica
A região crítica pode ser obtida selecionando $k$ de maneira que $R_c = \{\bar{X} < k \}$, sendo que $P(\bar{X} < k; H_0: \mu = \mu_0) = \alpha = 0.05$. Ou seja, sob $H_0$:

\footnotesize
$$P\left(\frac{\bar{X} - 200}{10/\sqrt(100)} \leq \frac{k - 200}{10/\sqrt(100)}\right) = P\left(Z < \frac{k - 200}{1}\right) = \alpha = 0.05$$

\small
Precisamos encontrar um $k$ que satisfaça a relação $P(Z < (k-200))=0.05$

O valor de $Z$ é obtido facilmente: $Z = \frac{195 - 200}{10/\sqrt(100)} = -5$

## Exemplo -- cont.

\small

### (iii) Região Crítica -- cont.
Nosso teste é unilateral ($H_1: \mu < 200 \mbox{ kg}$), então precisamos achar o valor de $P$ que divide a curva de probabilidade em $0.05$ e $0.95$.

$$Z + 200 < k$$
$$-5 + 200 < k$$
$$ 195 < k$$
$$P(k) = 0.05$$

\scriptsize
```{r}
#| tidy: true
#| echo: true
#| include: true
# qual valor divide a área da gaussiana
k <- qnorm(0.05,mean=200); k
```

$\Rightarrow R_c = \{\bar{X} < 198.3551\}$

## Exemplo -- cont.

\small

### (iv) Conclusão
Do enunciado, a média amostral vale 195. Logo, $\bar{x} = 195 \in R_c = \{\bar{X} < 198.3551\}$.

\textbf{Conclusão:} De acordo com os dados coletados e adotando um nível de significância de 5\%, concluímos que a resisstência média ao desmoronammento diminuiu.

## Método alternativo

\small

Um método alternativo \textbf{prático}: trabalhar diretamente na \textbf{escala Z}.

### Exemplo

\small

i. $H_0: \mu = \mu_0$ contra $H_1 : \mu < \mu_0$

ii. Estatística de teste:

\vspace{-0.3cm}\small
$$Z = \frac{\sqrt{n}(\bar{X}-\mu_0)}{\sigma} \underbrace{\sim}_{\mbox{sob } H_0 } N(0,1), \mbox{ pelo menos aproximadamente}$$

iii. Região crítica para um nível de significância $\alpha$ escolhido:

\small

:::: {.columns }

::: {.column  width="45%"}


$R_c = \{Z < z_\alpha\}$

iv. Se $z \in R_c = \{Z<z_\alpha\}$, rejeita-se $H_0$; caso contrário, não se rejeita $H_0$.

:::

::: {.column width="45%"}


\centering
\resizebox{!}{2.6cm}{
\includegraphics{figuras/teste-hipot-zalpha.png}
}

:::

::::

## Exemplo


\scriptsize
```{r}
#| tidy: true
#| echo: true
#| include: true
xbar = 195
mu0 = 200
sigma = 10
n = 100
z = (xbar - mu0)/(sigma/sqrt(n));z
alpha = 0.05
# este é o valor que divide a curva em 0.05 e 0.95
rc = qnorm(alpha);rc
```

\footnotesize

A estatística de teste z = `r z` está fora do intervalo da região de aceitação (ou seja, está na região crítica), `r z` $\in R_c$, `r z` $<$ `r round(-rc,3)`. Portanto, a um nível de significância de 5\%, nós rejeitamos a hipótese nula que a média seja igual a 200.

## Teste de hipóteses para uma média populacional

### Exercício

Suponha que o peso médio dos Pinguins Reis encontrados em uma colônia na Antártica no último ano foi 15.4 kg. Em uma amostra de 35 pinguins na mesma época neste ano, na mesma colônia, o peso médio foi 14.6kg. Assuma que o desvio padrão da população seja 2.5kg. A um nível de significância de 5\%, nós podemos rejeitar a hipótese nula de que o peso médio dos pinguins não difere do último ano?

i. As hipóteses são:

* $H_0 : \mu = 15.4$ kg
* $H_1 : \mu \neq 15.4$ kg

<!--
http://www.r-tutor.com/elementary-statistics/hypothesis-testing/two-tailed-test-population-mean-known-variance
-->

## Teste de hipóteses para uma média populacional

### Solução


\scriptsize
```{r}
#| tidy: true
#| echo: true
#| include: true
xbar = 14.6            # media da amostra
mu0 = 15.4             # valor da hipótese
sigma = 2.5            # desvio padrão da população
n = 35                 # tamanho da amostra 
z = (xbar-mu0)/(sigma/sqrt(n))  # estatística de teste
z
```
\footnotesize

Agora os valores críticos em um nível de significância de 0.05 (bilateral)


\scriptsize
```{r}
#| tidy: true
#| echo: true
#| include: true
alpha = 0.05
z.half.alpha = qnorm(1 - alpha/2)
c(-z.half.alpha,z.half.alpha)
```

\footnotesize
A estatística de teste z = `r round(z,4)` está entre os valores críticos `r round(c(-z.half.alpha,z.half.alpha),4)`, (está dentro da região de aceitação). Portanto, a um nível de significância de 0.05, nós **não** rejeitamos a hipótese nula de que o peso médio dos pinguins não difere do último ano.

## Teste de hipóteses para uma média populacional

### Solução -- alternativa

\footnotesize

Ao invés de se utilizar o valor crítico $z_c$, nós aplicamos a função `pnorm` para calcular o **p-value** da estatística de teste. A comparação é com o nível de significância $\alpha$ definido para o teste, no nosso caso $5\%$. Como nosso teste é bilateral, a área (probabilidade) em cada lado é de $\alpha/2 = 0.025$.

Temos duas alternativas:

* considerar o valor "dobrado" do `pnorm(z)` calculado, para comparar com o nível de significância $\alpha=0.05$, ou
* considerar o valor obtido no `pnorm(z)` e comparar com $\alpha/2=0.025$

Se o **p-value** obtido for maior do que o nível de significância, nós **não** rejeitamos a hipótese nula de que $\mu = 15.4$

Considerando o valor "dobrado" do **p-value**:
\scriptsize
```{r}
#| tidy: true
#| echo: true
#| include: true
pval = 2 * pnorm(z) # cauda inferior dobrada
pval
```
\footnotesize

Como o valor pval = `r round(pval,4)` é maior do que o nível de significância $\alpha$, nós **não rejeitamos** a hipótese nula de que a média seja 15.4

## Procedimento Geral de Teste de Hipótese

\centering
\resizebox{!}{7.5cm}{
\includegraphics{figuras/proced-geral-teste-hipot.png}
}

## Procedimento Geral de Teste de Hipótese

\centering
\resizebox{!}{7.5cm}{
\includegraphics{figuras/distrib-normal-e-t-student.png}
}

## Procedimento Geral de Teste de Hipótese

\centering
\resizebox{!}{7.5cm}{
\includegraphics{figuras/proced-geral-teste-hipot-iii.png}
}

## Procedimento Geral de Teste de Hipótese

### Exemplo

Se $n = 12$, são 11 graus de liberdade. Se tivermos $H_1: \mu \neq \mu_0$
escolhendo $\alpha = 0.05$, temos $p/2$ = $\alpha/2$, ou seja, $p = 0.05$.


\scriptsize
```{r}
#| tidy: true
#| echo: true
#| include: true
alpha = 0.05
df = 11
tc = qt(alpha/2,df = df);tc
```

### Exemplo

Se $n = 28$, são 27 graus de liberdade. Se tivermos $H_1: \mu < \mu_0$
escolhendo $\alpha = 0.01$, temos $p/2 = \alpha$, ou seja, $p = 2 \alpha = 0.02$.


\scriptsize
```{r}
#| tidy: true
#| echo: true
#| include: true
alpha = 0.02
df = 27
tc = qt(alpha/2,df = df);tc
```

## Exercício

\small

Dados históricos coletados em uma linha de produção de um certo item indicam 115 kg como massa média. A fim de testar a hipótese de que a média de itens recentemente produzidos se manteve, retirou-se, ao acaso, uma amostra de 20 itens, obtendo-se média igual a 118 kg e desvio padrão 20 kg. Utilize $\alpha = 0,05$.

### (i) As hipóteses de interesse são:
* $H_0: \mu = 115$ kg;
* $H_1: \mu \neq 115$ kg.

Utilize uma aproximação da distribuição das médias das 20 notas por uma distribuição normal, com média $\mu$ e variância $\sigma^2/n$

### (ii) Estatística de Teste:
$$ T = \frac{\sqrt{n}(\bar{X} - 115)}{S} \underbrace{\sim}_{\mbox{sob } H_0 } t(n-1)$$ 

## Exercício -- solução

\footnotesize
```{r}
#| tidy: true
#| echo: true
#| include: true
alpha = 0.05
df = 19
n = 20 # tamanho da amostra
S = 20 # desvio padrão da amostra
mu0 = 115
xbar = 118
tc <- qt(alpha/2,df=df); tc
Tt = (sqrt(n)*(xbar - mu0))/S; Tt
```

O valor da estatística de teste T = `r round(Tt,4)` está fora da Região Crítica, ou seja, $|T| <$ `r round(abs(tc),3)`. Portanto, **não rejeitamos** a $H_0$ a um nível de significância de 5\%. A diferença não é significativa.

## Teste de hipóteses para uma proporção populacional

O procedimento para testes de hipóteses sobre a proporção populacional (p) é semelhante ao utilizado para testes sobre uma média populacional.

### Problema

Testar a hipótese de que a proporção de sucessos de um ensaio de Bernoulli é igual a um valor especificado $p_0$. Isto é, testar um dos seguintes pares de hipóteses:

(i)

À esquerda     |   À direita      |   Bilateral
---------------|------------------|-----------------
$H_0: p = p_0$ | $H_0: p = p_0$   | $H_0: p = p_0$
$H_1: p < p_0$ | $H_1: p > p_0$   | $H_1: p \neq p_0$


## Teste de hipóteses para uma proporção populacional

(ii) Estatística de teste:

$$Z = \frac{\sqrt{n}(\bar{p}-p_0)}{\sqrt{p_0(1-p_0)}} \underbrace{\sim}_{\mbox{sob } H_0 } N(0,1), \mbox{ aproximadamente}$$

sendo que

$$\bar{p} = \frac{\mbox{Número de sucessos}}{n} = \frac{\sum_{i=1}^n X_i}{n}: \mbox{ estimador pontual de } p$$
é a \textbf{proporção amostral de sucessos} e $X_i = 1$, se o resultado for sucesso; $X_i = 0$ se o resultado for insucesso.

## Exemplo

Um estudo é realizado para determinar a presença de pequenas anomalias em chapas metálicas de uma certa dimensão. Segundo o fabricante, a proporção de chapas com anomalias é inferior a 25\%. Foram inspecionadas 50 chapas escolhidas ao acaso e sete delas apresentaram algum tipo de anomalia. Estes dados justificam a afirmação do fabricante? Adote um nível de significância igual a $0,05$.

(i) Hipóteses

$H_0: p = 0.25$ contra $H_1: p < 0.25$

(ii) Estatística de teste:

$$Z = \frac{\sqrt{50}(\bar{p}-0.25)}{\sqrt{0.25(1 - 0.25)}} \underbrace{\sim}_{\mbox{sob $H-0$}} N(0,1), \mbox{ aproximadamente}$$

## Exemplo

\footnotesize
(iii) Região Crítica para um nível de significância $\alpha = 0.05$:

\scriptsize
```{r}
#| tidy: true
#| echo: true
#| include: true
alpha = 0.05
rc_z <- qnorm(alpha);rc_z
```
\footnotesize
(iv) Temos $n =50$. Calculamos:

\scriptsize
```{r}
#| tidy: true
#| echo: true
#| include: true
n = 50
ne = 7
pbar = ne/n;pbar
p_0 = 0.25
z <- (sqrt(n)*(pbar - p_0))/(sqrt(p_0*(1-p_0)));z
```
\scriptsize
Como `r z` $\in R_c$, ou seja `r z` $<$ `r rc_z`, rejeita-se $H_0$ ao nível de significância de 5\%, ou seja, concluimos, a partir dos dados, que a proporção de chapas produzidas com anomalias é inferior a 25\%.

<!--
\textbf{Conclusão:} Adotando um nível de significância de 5\%, concluímos, a partir dos dados, que a proporção de chapas produzidas com anomalias é inferior a 25\%.
-->

<!-- https://www.analyticsvidhya.com/blog/2015/09/hypothesis-testing-explained/ -->

## Exemplo

\small
1. Os níveis de glicose no sangue para pacientes obesos tem uma média de 100 com um desvio padrão de 15. Um pesquisador acredita que uma dieta rica em amido de milho cru terá um efeito positivo nos níveis de glicose no sangue. Uma amostra de 36 pacientes que fizeram a dieta do amido de milho cru tiveram um nível de glicose médio de 108. Teste a hipótese de que o amido de milho cru foi (ou não) efetivo, a um nível de significância de 5\%.

(i) Hipótese: a média da população $\mu = 100$

$H_0: \mu= 100$ contra $H_1: \mu > 100$

(ii) Nível de significância: 5\% 

(iii) Calcular a estatística de teste, utilizando o \textit{z-score}

$$Z = \frac{\bar{X} - \mu_0}{\sigma/\sqrt{n}}$$

## Exemplo -- cont.


\scriptsize
```{r}
#| tidy: true
#| echo: true
#| include: true
mu_0 = 100
xbar = 108
sd = 15
n=36
z <- (xbar - mu_0)/(sd/sqrt(n));z
pvalue <- pnorm(z)
pvalue <- 1 - pvalue
```

\footnotesize

A probabilidade de termos um valor menor do que `r xbar` é `r round(pnorm(z),4)` e maior ou igual a 108, a probabilidade é $0.000687$


(iv) Este valor é menor do que o nível de significância de 5\%, de modo que rejeitamos a hipótese nula ($H_0$), isto é, \textbf{há algum efeito do amido de milho cru}.


## Exercício 1

Dois pesquisadores publicaram um artigo em 2002 onde relatam que a nota média da população na parte quantitativa de uma prova nacional (Graduate Record Examination -- GRE) para estudantes que fizeram o exame entre 1994 e 1997 foi $558 \pm 139$ ($\mu \pm \sigma$). Suponha que selecionemos uma amostra de 100 participantes ($n=100$). Registramos uma média da amostra igual a $585$. Calcule o \textit{p-value} para verificar se a hipótese nula ($\mu=558$) se mantém a um nível de significância de 0.05 ($\alpha = 0.05$).



## Exercício 2

Um pesquisador deseja estudar o efeito de certa substância no tempo de
reação de seres vivos a um certo tipo de estímulo.

Um experimento é desenvolvido com cobaias que são inoculadas com a
substância e submetidas a um estímulo elétrico, com seus tempos de
reação (em segundos) anotados. Os seguintes valores foram obtidos:
9.1; 9.3; 7.2; 7.5; 13.3; 10.9; 7.2; 9.9; 8.0; 8.6.

Admite-se que o tempo de reação segue o modelo Normal com média
8 e desvio padrão $\sigma = 2$ segundos. O pesquisador desconfia que o
tempo médio sofre alteração por influência da substância.

Efetue um teste de hipótese para verificar se o pesquisador tem razão.
Use $\alpha = 0.06$, e calcule a probabilidade do erro tipo II supondo
que $\mu = 9$.

## Exercício 3

Um relatório de uma companhia afirma que $40\%$ de toda a água obtida,
através de poços artesianos no nordeste, é salobra.

Há muitas controvérsias sobre essa afirmação, alguns dizem que a
proporção é maior, outros que é menor.

Para dirimir as dúvidas, $400$ poços foram sorteados e observou-se, em
$120$ deles água salobra. Qual seria a conclusão, ao nível de $3\%$?

## Variância desconhecida

### Teste para a média com variância desconhecida

Quando não conhecemos $\sigma^2$, usamos como
estimativa a variância amostral
$$
S^2 = \frac{1}{n-1} (\sum_{i=1}^{n} X_i^2 - n\bar{X}^2),
$$
e que a variável padronizada
$$
T = \frac{\bar{X} - \mu}{\sqrt{S^2/n}} = \frac{\bar{X} - \mu}{S/\sqrt{n}}
$$
segue uma distribuição *t-Student* com $n-1$ graus de liberdade, ou
seja,
$$
T \sim \, t_{(n-1)}
$$

## Exemplo 3

Deseja-se investigar se uma certa moléstia que ataca o rim altera o
consumo de oxigênio desse órgão. Para indivíduos sadios, admite-se que
esse consumo tem distribuição Normal com média 12 cm$^3$/min.

Os valores medidos em cinco pacientes com a moléstia foram: 14.4; 12.9;
15.1; 13.7; 13.5.

Qual seria a conclusão, ao nível de $1\%$ de significância?

## Testes Qui-Quadrado

<!--
https://online.stat.psu.edu/stat415/lesson/16   <- tem material muito bom pra acrescentar aqui
https://www.displayr.com/what-is-the-chi-square-test-of-homogeneity/  <- material bom, simples


-->


Os testes que utilizam o modelo **Qui-Quadrado** como estrutura
probabilística são denominados genericamente de **Testes Qui-Quadrado**.

Esse mesmo modelo pode ser utilizado para testes com finalidades
diferentes, por exemplo:

- **Teste de aderência**: verifica se uma variável segue uma determinada
  distribuição
- **Teste de independência**: verifica a independência entre duas
  variáveis
- **Teste de homogeneidade**: verifica se uma variável se comporta de
  maneira similar em várias subpopulações


## Testes Qui-Quadrado (cont.)

De maneia geral, qualquer teste Qui-Quadrado envolve a quantidade
$$
Q^2 = \sum_{i,j} \frac{(o_{ij} - e_{ij})^2}{e_{ij}}
$$
que mede as discrepâncias entre **frequências observadas** ($o_{ij}$) e
as **frequências esperadas** ($e_{ij}$). Pode-se mostrar que $Q^2$
possui distribuição Qui-Quadrado com $\nu$ **graus de liberdade**, ou
seja,
$$
Q^2 \sim \chi^2_\nu
$$
onde $\nu$ depende do teste utilizado.

A **Região Crítica** (RC) é constituída de valores grandes de $Q^2$,
$$
RC = \{\omega : \omega \geq q_c\}
$$
com $q_c$ sendo determinado pelo nível de significância do teste
$$
\alpha = P(Q^2 \geq q_c \, | \, H_0 \text{ verdadeira})
$$

## Distribuição Qui-Quadrado

```{r}
#| label: qui
#| fig.width: 7.0
#| fig.height: 5.0
#| out.width: 80%
qui <- function(x) {dchisq(x, df = 4)}
curve(qui, from = 0, to = 20,
      ylab = "", xlab = expression(Q^2), axes = FALSE)
box()
qc <- qchisq(0.05, df = 4, lower.tail = FALSE)
axis(1, at = c(0, qc), labels = c(0, expression(q[c])))
cord.x <- c(qc, seq(qc, 20, 0.01), 20)
cord.y <- c(0, dchisq(seq(qc, 20, 0.01), df = 4), 0)
polygon(x = cord.x, y = cord.y, col = "gray", border = NA)
legend("topright", legend = "RC", fill = "gray")
text(x = qc, y = 0.005, labels = expression(alpha), pos = 4)
```

## Exemplo 4 (teste de aderência)

No exemplo 2, definimos $X$ como sendo o número de impactos anteriores
à falha em um equipamento eletrônico.

Uma amostra de $80$ ensaios foi obtida, cada ensaio representando os
testes feitos até a interrupção por falha no equipamento, resultado 80
observações da variável de interesse.

Pretende-se verificar se o modelo Geométrico com $p = 0.4$ é adequado.

## Exemplo 5 (teste de independência)

A tabela abaixo contém os resultados obtidos por estudantes do ensino
médio, em um exame com questões nas disciplinas de física e matemática.
Para efeito de apresentação na tabela e análise de comportamento, as
notas foram classificadas nas categorias alta, média e baixa.

```{r}
M <- rep(c("Alta", "Média", "Baixa"), times = c(117, 276, 135))
F <- c(rep(c("Alta", "Média", "Baixa"), times = c(56, 47, 14)),
       rep(c("Alta", "Média", "Baixa"), times = c(71, 163, 42)),
       rep(c("Alta", "Média", "Baixa"), times = c(12, 38, 85)))
F <- factor(F, levels = c("Alta", "Média", "Baixa"))
M <- factor(M, levels = c("Alta", "Média", "Baixa"))
addmargins(table(F, M))
```

Deseja-se testar se existe dependência entre as notas dessas duas
disciplinas.

## Exemplo 5 (teste de independência)

Vamos testar as hipóteses:
\begin{align*}
H_0 &: \text{As notas de física e matemática são independentes} \\
H_a &: \text{As notas não são independentes}
\end{align*}
Para isso, construímos uma tabela de valores esperados para a casela
$i,j$:
$$
e_{i,j} = \frac{\text{Total da linha } i \times \text{Total da coluna }
j}{\text{Total geral}}
$$
E assim, obtemos
```{r}
## Totais
tl <- apply(table(F, M), 1, sum)
tc <- apply(table(F, M), 2, sum)
tg <- sum(tl)
## Para calcular as entradas
tab <- expand.grid(tl = tl, tc = tc)
## Matriz esperada
esp <- matrix(round((tab$tl * tab$tc)/tg, 2), nrow = 3)
rownames(esp) <- colnames(esp) <- c("Alta", "Média", "Baixa")
esp
```

## Exemplo 5 (teste de independência)

Calculamos
$$
q^2_{obs} = \frac{(56 - 30.8)^2}{30.8} + \cdots + \frac{(85 -
36.05)^2}{36.05} = 145.78
$$
Nesse caso, $Q^2$ possui distribuição Qui-Quadrado com $(r-1) \times
(s-1)$ graus de liberdade ($r$ linhas e $s$ colunas). Para $\alpha =
0.01$
$$
P(Q^2 \geq q_c \, | \, H_0) = \alpha \Rightarrow
 P(Q^2 \geq q_c \, | \, H_0) = 0.01
$$
obtemos $q_c = 13.28$ para $\chi^2_4$, e portanto,
$$
R_C = \{\omega : \omega \geq 13.28\}.
$$
Como $q^2_{obs} \in R_C$, concluímos por rejeitar a hipótese nula (de
independência entras as notas).


---

\centering
\huge\bf\color{black!80!green}{That's all folks!}
